{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_Lachlan_Sharp_web_crawler.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tyLwJlF9R8NL8hTh-VDMURq9OVqQOX4b",
      "authorship_tag": "ABX9TyMjxzBMVuwxEX+0WH8+kHzJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LachlanSharp/Lorem-ipsum/blob/main/A3_Lachlan_Sharp_web_crawler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb1PvzncnGBd"
      },
      "source": [
        "# MA5851 - Assessment 3: WebCrawler and NLP System\n",
        "\n",
        "---\n",
        "\n",
        "* **Author**: Lachlan Sharp\n",
        "* **Due Date**: 2021-12-08\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<div style=\"font-size:8pt; background-color:WhiteSmoke; padding-left:32px;\">\n",
        "\n",
        "\\  \n",
        "\n",
        "*Note*: It is recommended that the ***Table of contents*** be used within Google Colab when reviewing this notebook for ease of navigation and overview of this data-project's structure.\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txHzM7fKzhak"
      },
      "source": [
        "---\n",
        "\n",
        "# Setup of data-project "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfad1tSKhvzj"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgmbsYikhoE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "700b5860-ca98-4c1b-ed19-a2ac5a71c6fd"
      },
      "source": [
        "import os.path # Operating system interface\n",
        "from time import time, sleep # Time access and conversions\n",
        "from datetime import datetime # Basic date and time types\n",
        "import glob # Unix style pathname pattern expansio\n",
        "\n",
        "import numpy as np # array/matrices support\n",
        "import pandas as pd # data analaysis\n",
        "\n",
        "import requests # HTTP library\n",
        "from bs4 import BeautifulSoup # HTML/XML document parser\n",
        "import html # HyperText Markup Language support\n",
        "\n",
        "import re # regular expressions\n",
        "\n",
        "\n",
        "# Get python version\n",
        "import platform # Platform’s identifying data\n",
        "print('\\nPython version {}'.format(platform.python_version()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Python version 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQhVyeQjws3J"
      },
      "source": [
        "## Set directory paths\n",
        "\n",
        "Set pertinent file paths and names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqg9KLiezoUg"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "This section applies to use of this Python notebook within Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BOZaHKeyQr_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4043931e-099c-43db-a898-0b9714751efc"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1ThXe1I69ga"
      },
      "source": [
        "### Set file paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYqAA03QiNjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a96ec3d-2576-4d97-b6c2-ab55207e794b"
      },
      "source": [
        "def mk_dir(path):\n",
        "    \"\"\"\n",
        "    Creates a directory if it doesn't exist\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    str : path\n",
        "        The full directory path for the folder to be created.\n",
        "        Note: the path should not terminate with a '/'\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    bool\n",
        "        If folder exists, True, otherwise, False\n",
        "    \"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        try:\n",
        "            os.makedirs(path)\n",
        "        except:\n",
        "            pass\n",
        "    return os.path.exists(path)\n",
        "\n",
        "# Set directory paths root filepath for data-project\n",
        "filepath_root = '/content/drive/MyDrive/Colab Notebooks/MA5851/Assessment 3' # data-project root\n",
        "filepath_data = os.path.join(filepath_root, 'data') # data folder\n",
        "print(\"Directory 'data' exists?: {}\".format(mk_dir(filepath_data)))\n",
        "\n",
        "# Set filenames\n",
        "filename_tophorse_items_df = \"df_tophorse_items.csv\"\n",
        "filename_tophorse_item_details_df = \"df_tophorse_item_details.csv\"\n",
        "\n",
        "filename_horseforum_threads_df = \"df_horseforum_threads.csv\" \n",
        "filename_horseforum_thread_posts_df = \"df_horseforum_thread_posts.csv\"\n",
        "filename_horseforum_thread_pages_df = \"df_horseforum_thread_pages.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 'data' exists?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxOxDSnfgIEO"
      },
      "source": [
        "## User defined functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpKPBwDMsy0G"
      },
      "source": [
        "# WebCrawler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqNe84mpxAgu"
      },
      "source": [
        "def web_crawler(\n",
        "    url_domain\n",
        "    ,url_path\n",
        "    ,fx_get_ResultSet\n",
        "    ,fx_get_ResultSet_data\n",
        "    ,fx_get_next_page_url    \n",
        "    ,fx_get_page_data = None\n",
        "    ,max_pages = None\n",
        "    ,echo_every_n = 1\n",
        "    ,wait_page_sec = 0\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Generic web crawler\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    str : url_domain\n",
        "        The base URL domain (including protocol) to be crawled (e.g., https://www.tophorse.com.au)\n",
        "    str : url_path\n",
        "        The URL path for the first page to be crawled (e.g. /horses-for-sale/)\n",
        "        Note that the full URL is formed via concatenation with url_domain, hence\n",
        "        care should be taken to provide the correct prefixing & suffixing '/'\n",
        "    function : fx_get_ResultSet\n",
        "        A function to return a BeautifulSoup ResultSet object; \n",
        "        this will be  a collection of items (i.e., tags) within the page being crawled.\n",
        "    function : fx_get_ResultSet_data\n",
        "        A function that returns scraped data from a ResultSet, as a list;\n",
        "        this will be data from the collection of items (i.e., tags) returned by `fx_get_ResultSet()`.\n",
        "    function : fx_get_next_page_url\n",
        "        A function that returns the \"next\" page's url path as a string; \n",
        "        this will be specific for the page being crawled.\n",
        "    function : fx_get_page_data\n",
        "        An optional function that returns scraped data from the page being crawled, as a dictionary;\n",
        "        this will be data of the page itself, as opposed to data from the collection of items within\n",
        "        the page returned by `fx_get_ResultSet_data()`.        \n",
        "    int : max_pages\n",
        "        The maximum number of pages to iterate (handy for when still tesing code)\n",
        "    int : echo_every_n\n",
        "        prints output every n iterations, where n = echo_every_n.\n",
        "    int : wait_page_sec\n",
        "        Duration in seconds to wait between requesting pages\n",
        "    \"\"\"\n",
        "    # Initialise\n",
        "    if max_pages is None:\n",
        "        max_pages = float('inf') \n",
        "    data_pages = [] \n",
        "    data_items = []\n",
        "    count_page = 1\n",
        "\n",
        "    # Crawl through pages until `url_path` is an empty string.\n",
        "    while (url_path != \"\") and (count_page <= max_pages):\n",
        "        response = requests.get(url_domain + url_path)\n",
        "\n",
        "        # Echo progress\n",
        "        if (echo_every_n > 0) and (count_page % echo_every_n == 0): # lazy evaluation\n",
        "            print('Page {}, HTTP response status: {}'.format(count_page, response.status_code))\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            # Scrape page\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        " \n",
        "            # Get data of the page itself (optional)\n",
        "            if fx_get_page_data is not None:\n",
        "                page_data = fx_get_page_data(soup)\n",
        "                page_data['page_url_path'] = url_path # Add key\n",
        "                # Append results\n",
        "                data_pages.extend([page_data])\n",
        "\n",
        "            # Get data from a collection of items within the page\n",
        "            tags = fx_get_ResultSet(soup)\n",
        "            item_data = fx_get_ResultSet_data(tags)\n",
        "\n",
        "            # Append results\n",
        "            data_items.extend(item_data)\n",
        "            if (echo_every_n > 0) and (count_page % echo_every_n == 0): # lazy evaluation\n",
        "                print(\"\\t{} items...\".format(len(item_data)))\n",
        "\n",
        "            # Get next page url\n",
        "            url_path = fx_get_next_page_url(soup)\n",
        "            #print(url_path)\n",
        "        else:\n",
        "            # force condition to exit loop\n",
        "            url_path = \"\"\n",
        "\n",
        "        count_page += 1\n",
        "        sleep(wait_page_sec)\n",
        "    \n",
        "    return data_items, data_pages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyi6mvJgqxAK"
      },
      "source": [
        "## tophorse sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LviqjvGcHJBC"
      },
      "source": [
        "### UDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TbZXpgBqvxU"
      },
      "source": [
        "def get_next_page_url_tophorse(tophorse_soup):\n",
        "    \"\"\"\n",
        "    Gets the 'next page' url path from the www.tophorse.com.au main page.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : tophorse_soup\n",
        "        A BeautifulSoup object for the web page.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        the relative url path for the 'next page' if successful, otherwise an empty string.\n",
        "    \"\"\"\n",
        "    soup = tophorse_soup\n",
        "    url_path = \"\"\n",
        "    try:\n",
        "        url_path = soup.find(\n",
        "            'div'\n",
        "            ,id = 'catalogueMidCol'\n",
        "            ).find(\n",
        "                'a'\n",
        "                ,class_='redLink'\n",
        "                ,string=re.compile(\"^Next\")\n",
        "                )['href']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return url_path\n",
        "\n",
        "\n",
        "\n",
        "def get_listings_tophorse(tophorse_soup):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : tophorse_soup\n",
        "        A BeautifulSoup object for the web page.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    bs4.element.ResultSet\n",
        "        An iterable collection of advert listings, as returned by BeautifulSoup\n",
        "    \"\"\"\n",
        "    soup = tophorse_soup\n",
        "    return soup.find_all('div', class_='listAdvert hd')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def scrape_listing_details_tophorse(advert_listings):\n",
        "    \"\"\"\n",
        "    Iterates a bs4 ResultSet of horse advert (i.e., www.tophorse.com.au) listings \n",
        "    to get predefined values.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.element.ResultSet : advert_listings\n",
        "        An iterable collection of advert listings, as returned by BeautifulSoup\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    list of dict {str, Any}\n",
        "        the predefined details of each advert\n",
        "            + item_title\n",
        "            + item_url_path\n",
        "            + item_created_date\n",
        "            + item_img_url_path\n",
        "    \"\"\"\n",
        "    listings = advert_listings\n",
        "    data_items=[]\n",
        "    if listings is not None:\n",
        "        for item in listings:\n",
        "            # initialise\n",
        "            item_title = \"\"\n",
        "            item_url_path = \"\"\n",
        "            item_created_date = \"\"\n",
        "            item_img_url_path = \"\"\n",
        "\n",
        "            # Get items's listing title and url path\n",
        "            try:\n",
        "                tag1 = item.find('h2', class_='listAdvertTitle')\n",
        "                tag_url = tag1.find('a')\n",
        "                itemt_title = tag_url.get_text()\n",
        "                item_url_path = tag_url['href']\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Get items's image\n",
        "            try:\n",
        "                item_img_url_path = item.find('div', class_='advertImage').find('a').img['src']\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Get items's created date\n",
        "            try:\n",
        "                item_created_date = tag1.find('span').get_text()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Save result\n",
        "            dict_item = {\n",
        "                'item_title' : item_title\n",
        "                ,'item_url_path' : item_url_path\n",
        "                ,'item_created_date' : item_created_date\n",
        "                ,'item_img_url_path' : item_img_url_path\n",
        "                }\n",
        "            data_items.append(dict_item.copy())\n",
        "\n",
        "    return data_items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlZ51o37N9j"
      },
      "source": [
        "### Crawl TopHorse listings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJzUj3KlLlGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0547ea18-5216-45cc-d2fc-5de22d7513b0"
      },
      "source": [
        "# Specify which web page should be crawled\n",
        "url_domain =  \"https://www.tophorse.com.au\"\n",
        "url_path = \"/horses-for-sale/\" # note terminating '/'\n",
        "\n",
        "# Set functions relevant to scraping the web page\n",
        "get_ResultSet = get_listings_tophorse\n",
        "get_ResultSet_data = scrape_listing_details_tophorse\n",
        "get_next_page_url = get_next_page_url_tophorse\n",
        "\n",
        "# Crawl pages and scrape\n",
        "start_time = time()\n",
        "print('Crawl start UTC: {}'.format(datetime.fromtimestamp(start_time)))\n",
        "data_tophorse_items, _ = web_crawler(\n",
        "    url_domain =  url_domain\n",
        "    ,url_path = url_path\n",
        "    ,fx_get_ResultSet = get_ResultSet\n",
        "    ,fx_get_ResultSet_data = get_ResultSet_data\n",
        "    ,fx_get_next_page_url = get_next_page_url \n",
        "    ,echo_every_n = 1   \n",
        ")\n",
        "end_time = time()\n",
        "print(\"---crawl complete---\")\n",
        "print()\n",
        "print(\"Listings count: {}\".format(len(data_tophorse_items)))\n",
        "print(\"Crawl time (sec): {0}\".format(end_time - start_time))\n",
        "print('Crawl end UTC: {}'.format(datetime.fromtimestamp(end_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crawl start UTC: 2021-11-30 13:40:45.652615\n",
            "Page 1, HTTP response status: 200\n",
            "\t15 items...\n",
            "Page 2, HTTP response status: 200\n",
            "\t15 items...\n",
            "Page 3, HTTP response status: 200\n",
            "\t15 items...\n",
            "Page 4, HTTP response status: 200\n",
            "\t14 items...\n",
            "Page 5, HTTP response status: 200\n",
            "\t13 items...\n",
            "Page 6, HTTP response status: 200\n",
            "\t14 items...\n",
            "Page 7, HTTP response status: 200\n",
            "\t13 items...\n",
            "Page 8, HTTP response status: 200\n",
            "\t14 items...\n",
            "Page 9, HTTP response status: 200\n",
            "\t13 items...\n",
            "Page 10, HTTP response status: 200\n",
            "\t14 items...\n",
            "Page 11, HTTP response status: 200\n",
            "\t15 items...\n",
            "Page 12, HTTP response status: 200\n",
            "\t12 items...\n",
            "Page 13, HTTP response status: 200\n",
            "\t3 items...\n",
            "Page 14, HTTP response status: 200\n",
            "\t0 items...\n",
            "---crawl complete---\n",
            "\n",
            "Listings count: 170\n",
            "Crawl time (sec): 15.835863828659058\n",
            "Crawl end UTC: 2021-11-30 13:41:01.488478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QNS26v5Y1kCQ",
        "outputId": "6704255e-8a00-439f-e6f1-0556f7333e70"
      },
      "source": [
        "# Convert to data frame and save result locally\n",
        "df_tophorse_items = pd.DataFrame(data_tophorse_items)\n",
        "\n",
        "# Save dataframe locally\n",
        "df_tophorse_items.to_csv(os.path.join(filepath_data, filename_tophorse_items_df), index=False)\n",
        "\n",
        "df_tophorse_items"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_title</th>\n",
              "      <th>item_url_path</th>\n",
              "      <th>item_created_date</th>\n",
              "      <th>item_img_url_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/paint-horse/Buckskin-Paint-Co...</td>\n",
              "      <td>30/11/2021</td>\n",
              "      <td>/images/ResizedImages/30-11-21-296166Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/endurance-and-trail/Vee-Rock-...</td>\n",
              "      <td>30/11/2021</td>\n",
              "      <td>/images/ResizedImages/30-11-21-488434Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/ponies/Tory__27-11-21-563432</td>\n",
              "      <td>27/11/2021</td>\n",
              "      <td>/images/ResizedImages/27-11-21-586832Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/australian-stock-horse/Johnny...</td>\n",
              "      <td>27/11/2021</td>\n",
              "      <td>/images/ResizedImages/27-11-21-562895Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/broodmare/Wanted---Riding-Pon...</td>\n",
              "      <td>26/11/2021</td>\n",
              "      <td>/images/ResizedImages/24-11-21-231789Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/allrounder-pony/Tilly__16-12-...</td>\n",
              "      <td>17/12/2019</td>\n",
              "      <td>/images/ResizedImages/16-12-19-224877Image7_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/allrounder-horse/Grey-TB-mare...</td>\n",
              "      <td>04/12/2019</td>\n",
              "      <td>/images/ResizedImages/4-12-19-248828Image1_w22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/allrounder-pony/stunning-pony...</td>\n",
              "      <td>04/12/2019</td>\n",
              "      <td>/images/ResizedImages/4-12-19-214163Image3_w22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/allrounder-pony/amazing-Bitle...</td>\n",
              "      <td>03/12/2019</td>\n",
              "      <td>/images/ResizedImages/3-12-19-723137Image1_w22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td></td>\n",
              "      <td>/horses-for-sale/allrounder-horse/Thoroughbred...</td>\n",
              "      <td>01/12/2019</td>\n",
              "      <td>/images/ResizedImages/1-12-19-779872Image1_w22...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    item_title  ...                                  item_img_url_path\n",
              "0               ...  /images/ResizedImages/30-11-21-296166Image1_w2...\n",
              "1               ...  /images/ResizedImages/30-11-21-488434Image1_w2...\n",
              "2               ...  /images/ResizedImages/27-11-21-586832Image1_w2...\n",
              "3               ...  /images/ResizedImages/27-11-21-562895Image1_w2...\n",
              "4               ...  /images/ResizedImages/24-11-21-231789Image1_w2...\n",
              "..         ...  ...                                                ...\n",
              "165             ...  /images/ResizedImages/16-12-19-224877Image7_w2...\n",
              "166             ...  /images/ResizedImages/4-12-19-248828Image1_w22...\n",
              "167             ...  /images/ResizedImages/4-12-19-214163Image3_w22...\n",
              "168             ...  /images/ResizedImages/3-12-19-723137Image1_w22...\n",
              "169             ...  /images/ResizedImages/1-12-19-779872Image1_w22...\n",
              "\n",
              "[170 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBflpXuNAcnL"
      },
      "source": [
        "### Reload data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hvjQcpH3Kljr",
        "outputId": "fd09ce08-5dcd-46a5-c452-22868b593a80"
      },
      "source": [
        "# Reload tophorse listings\n",
        "df_tophorse_items = pd.read_csv(os.path.join(filepath_data, filename_tophorse_items_df))\n",
        "df_tophorse_items"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_title</th>\n",
              "      <th>item_url_path</th>\n",
              "      <th>item_created_date</th>\n",
              "      <th>item_img_url_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/paint-horse/Buckskin-Paint-Co...</td>\n",
              "      <td>30/11/2021</td>\n",
              "      <td>/images/ResizedImages/30-11-21-296166Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/endurance-and-trail/Vee-Rock-...</td>\n",
              "      <td>30/11/2021</td>\n",
              "      <td>/images/ResizedImages/30-11-21-488434Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/ponies/Tory__27-11-21-563432</td>\n",
              "      <td>27/11/2021</td>\n",
              "      <td>/images/ResizedImages/27-11-21-586832Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/australian-stock-horse/Johnny...</td>\n",
              "      <td>27/11/2021</td>\n",
              "      <td>/images/ResizedImages/27-11-21-562895Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/broodmare/Wanted---Riding-Pon...</td>\n",
              "      <td>26/11/2021</td>\n",
              "      <td>/images/ResizedImages/24-11-21-231789Image1_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/allrounder-pony/Tilly__16-12-...</td>\n",
              "      <td>17/12/2019</td>\n",
              "      <td>/images/ResizedImages/16-12-19-224877Image7_w2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/allrounder-horse/Grey-TB-mare...</td>\n",
              "      <td>04/12/2019</td>\n",
              "      <td>/images/ResizedImages/4-12-19-248828Image1_w22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/allrounder-pony/stunning-pony...</td>\n",
              "      <td>04/12/2019</td>\n",
              "      <td>/images/ResizedImages/4-12-19-214163Image3_w22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/allrounder-pony/amazing-Bitle...</td>\n",
              "      <td>03/12/2019</td>\n",
              "      <td>/images/ResizedImages/3-12-19-723137Image1_w22...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>NaN</td>\n",
              "      <td>/horses-for-sale/allrounder-horse/Thoroughbred...</td>\n",
              "      <td>01/12/2019</td>\n",
              "      <td>/images/ResizedImages/1-12-19-779872Image1_w22...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     item_title  ...                                  item_img_url_path\n",
              "0           NaN  ...  /images/ResizedImages/30-11-21-296166Image1_w2...\n",
              "1           NaN  ...  /images/ResizedImages/30-11-21-488434Image1_w2...\n",
              "2           NaN  ...  /images/ResizedImages/27-11-21-586832Image1_w2...\n",
              "3           NaN  ...  /images/ResizedImages/27-11-21-562895Image1_w2...\n",
              "4           NaN  ...  /images/ResizedImages/24-11-21-231789Image1_w2...\n",
              "..          ...  ...                                                ...\n",
              "165         NaN  ...  /images/ResizedImages/16-12-19-224877Image7_w2...\n",
              "166         NaN  ...  /images/ResizedImages/4-12-19-248828Image1_w22...\n",
              "167         NaN  ...  /images/ResizedImages/4-12-19-214163Image3_w22...\n",
              "168         NaN  ...  /images/ResizedImages/3-12-19-723137Image1_w22...\n",
              "169         NaN  ...  /images/ResizedImages/1-12-19-779872Image1_w22...\n",
              "\n",
              "[170 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEJK_WvY7TqF"
      },
      "source": [
        "### Crawl listing details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx_0bypoOecj",
        "outputId": "324e2a5d-0b62-4e05-9942-fab24f8e46e6"
      },
      "source": [
        "# Crawl pages and scrape\n",
        "start_time = time()\n",
        "print('Crawl start UTC: {}'.format(datetime.fromtimestamp(start_time)))\n",
        "\n",
        "df_item_details = pd.DataFrame()\n",
        "count_max = df_tophorse_items.shape[0]\n",
        "echo_every_n = 10\n",
        "for count, url_path in enumerate(df_tophorse_items['item_url_path']):\n",
        "    # Requeste advert details\n",
        "    url_item = url_domain + url_path\n",
        "    status_code = 0\n",
        "    try:\n",
        "        response = requests.get(url_item)\n",
        "        status_code = response.status_code\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        # Target machine actively refused connection\n",
        "        status_code = \"connection refused\"\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Show progress\n",
        "    if (echo_every_n > 0) and (count % echo_every_n == 0): # lazy evaluation\n",
        "        print(\"item {} of {}:\".format(count + 1, count_max))\n",
        "        print(\"\\t{}\".format(url_item))\n",
        "        print('\\tHTTP response status: {}'.format(status_code))\n",
        "\n",
        "    df_item = pd.DataFrame({ 'url_path':  [url_path] })\n",
        "\n",
        "    if status_code == 200:\n",
        "        # Initialsie\n",
        "        item_description, main_image_url_path, video_url, Seller_Id = \"\", \"\", \"\", \"\"\n",
        "        df_table_details = pd.DataFrame()\n",
        "        image_count = 0\n",
        "        parents = [ '', '']\n",
        "        grand_parents = [ '', '', '', '']\n",
        "        great_grand_parents = [ '', '', '', '']     \n",
        "\n",
        "        try: # Item description\n",
        "            item_description = soup.find('div', class_='itemDescription').get_text()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try: # Details table\n",
        "            table_details = soup.find('table', class_='productPageItemDetails')\n",
        "            df_table_details = pd.read_html(table_details.prettify())[0]\n",
        "            df_table_details.rename(columns={0: 'key', 1: 'value'}, inplace=True)\n",
        "            df_table_details = df_table_details.iloc[:df_table_details[df_table_details['key'].str.contains('(?i)^contact', regex= True)].index[0], ]\n",
        "            df_table_details['key'] = df_table_details['key'].str.replace(':','')\n",
        "            df_table_details.set_index('key', inplace=True)\n",
        "            df_table_details = df_table_details.transpose()\n",
        "            df_table_details.reset_index(inplace=True)\n",
        "            df_table_details            \n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try: # Breeding Tree\n",
        "            table_breeding_tree = soup.find('table', class_='breedingTree')\n",
        "            df_table_breeding_tree = pd.read_html(table_breeding_tree.prettify())[0]\n",
        "            df_table_breeding_tree.rename(columns={0: 'parents', 1: 'grand_parents', 2: 'great_grand_parents'}, inplace=True)\n",
        "            df_table_breeding_tree.fillna('', inplace=True)\n",
        "            parents = df_table_breeding_tree[df_table_breeding_tree.index % 4 == 0]['parents'].tolist()\n",
        "            grand_parents = df_table_breeding_tree[df_table_breeding_tree.index % 2 == 0]['grand_parents'].tolist()\n",
        "            great_grand_parents = df_table_breeding_tree['great_grand_parents'].tolist()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try: # Number of images\n",
        "            image_count = len(soup.find('div', class_='contentBlock').find_all('img'))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try: # Main image url_path\n",
        "            main_image_url_path = soup.find('div', class_='mainImage').find('img')['src']\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try: # Video url\n",
        "            video_url = soup.find('div', id='videoContent').find('iframe')['src']\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        try: # Seller Id\n",
        "            Seller_Id = soup.find('div', class_='productPageRightCol').find('a', id=re.compile(r'SellersOtherAdverts$'))['href']\n",
        "            Seller_Id = re.findall(r'[^/]+$', Seller_Id)[0]\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Set item results\n",
        "        df_item = pd.DataFrame({ 'url_path':  [url_path] })\n",
        "        df_item['Description'] = item_description\n",
        "        df_item = pd.concat([df_item.reset_index(drop=True), df_table_details], axis=1)\n",
        "        df_item['image_count'] = image_count\n",
        "        df_item['main_image_url_path'] = main_image_url_path\n",
        "        df_item['video_url'] = video_url\n",
        "        df_item['Seller_Id'] = Seller_Id\n",
        "        df_item['parents'] = \";\".join(parents)\n",
        "        df_item['grand_parents'] = \";\".join(grand_parents)\n",
        "        df_item['great_grand_parents'] = \";\".join(great_grand_parents)\n",
        "\n",
        "    df_item_details = pd.concat([df_item_details, df_item])\n",
        "\n",
        "df_item_details.reset_index(inplace=True)\n",
        "df_tophorse_item_details = df_item_details.drop(df_item_details.columns[0], axis=1).copy()\n",
        "\n",
        "# A horses category on the sight is hard-coded into its URL path e.g., \n",
        "#    https://www.tophorse.com.au/horses-for-sale/ --> `performance-horse` <-- /Super-quiet-educated-gelding-__9-1-20-596629\n",
        "df_tophorse_item_details['category'] = df_tophorse_item_details['url_path'].replace({ r'/horses-for-sale/([^/]+)/.*' : r'\\1' }, regex = True, inplace=False)\n",
        "del df_item_details\n",
        "\n",
        "end_time = time()\n",
        "print(\"---crawl complete---\")\n",
        "print()\n",
        "print(\"Listings count: {}\".format(len(df_tophorse_item_details.index)))\n",
        "print(\"Crawl time (sec): {0}\".format(end_time - start_time))\n",
        "print('Crawl end UTC: {}'.format(datetime.fromtimestamp(end_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crawl start UTC: 2021-11-30 13:42:50.237417\n",
            "item 1 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/paint-horse/Buckskin-Paint-Colt-__30-11-21-178636\n",
            "\tHTTP response status: 200\n",
            "item 11 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/australian-stock-horse/Stock-horse-for-sale-__22-11-21-474731\n",
            "\tHTTP response status: 200\n",
            "item 21 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/ex-racehorse/FOR-LEASE---beautiful-OTTB-__12-11-21-637184\n",
            "\tHTTP response status: 200\n",
            "item 31 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/allrounder-horse/Luke__19-10-21-822854\n",
            "\tHTTP response status: 200\n",
            "item 41 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/allrounder-horse/Phoenix__21-9-21-519817\n",
            "\tHTTP response status: 200\n",
            "item 51 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/allrounder-horse/HRV-Hero--Parisian-Pride--Paris-__5-8-21-116345\n",
            "\tHTTP response status: 200\n",
            "item 61 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/performance-horse/F-rst-Love-x-Versace-Black-Colt__15-7-21-919789\n",
            "\tHTTP response status: 200\n",
            "item 71 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/dressage-pony/Glen-J-San-Remo__26-5-21-397355\n",
            "\tHTTP response status: 200\n",
            "item 81 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/dressage-horse/Blingy-OTTB-Bay-Mare-__9-3-21-142491\n",
            "\tHTTP response status: 200\n",
            "item 91 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/endurance-and-trail/Allrounder-4-Intermediate-Rider-__11-1-21-653444\n",
            "\tHTTP response status: 200\n",
            "item 101 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/allrounder-pony/Allenmore-Standing-Ovation----EOI__19-11-20-249938\n",
            "\tHTTP response status: 200\n",
            "item 111 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/allrounder-horse/One-in-a-Million__28-6-20-933612\n",
            "\tHTTP response status: 200\n",
            "item 121 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/allrounder-horse/QH-mare__17-8-20-913164\n",
            "\tHTTP response status: 200\n",
            "item 131 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/arabian/Quality-Filly-by-RHR-Heir-of-Marwan__26-5-20-718178\n",
            "\tHTTP response status: 200\n",
            "item 141 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/family-friend/Coloured-Miniature-Show-Gelding__17-4-20-693626\n",
            "\tHTTP response status: 200\n",
            "item 151 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/mountain-and-moorland/BAMBOROUGH-DOOP-DOOP-DEE-DO__5-3-20-363618\n",
            "\tHTTP response status: 200\n",
            "item 161 of 170:\n",
            "\thttps://www.tophorse.com.au/horses-for-sale/performance-horse/Super-quiet-educated-gelding-__9-1-20-596629\n",
            "\tHTTP response status: 200\n",
            "---crawl complete---\n",
            "\n",
            "Listings count: 170\n",
            "Crawl time (sec): 184.10685467720032\n",
            "Crawl end UTC: 2021-11-30 13:45:54.344272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "id": "A9pbe5bne6F3",
        "outputId": "541e53e1-6e95-446d-a447-9361cfae4f0d"
      },
      "source": [
        "# Save dataframe locally\n",
        "df_tophorse_item_details.to_csv(os.path.join(filepath_data, filename_tophorse_item_details_df), index=False)\n",
        "df_tophorse_item_details"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url_path</th>\n",
              "      <th>Description</th>\n",
              "      <th>index</th>\n",
              "      <th>Height</th>\n",
              "      <th>Age</th>\n",
              "      <th>Colour</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Breed</th>\n",
              "      <th>Terms</th>\n",
              "      <th>Location</th>\n",
              "      <th>P/Trade</th>\n",
              "      <th>Price</th>\n",
              "      <th>Ad Code</th>\n",
              "      <th>image_count</th>\n",
              "      <th>main_image_url_path</th>\n",
              "      <th>video_url</th>\n",
              "      <th>Seller_Id</th>\n",
              "      <th>parents</th>\n",
              "      <th>grand_parents</th>\n",
              "      <th>great_grand_parents</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/horses-for-sale/paint-horse/Buckskin-Paint-Co...</td>\n",
              "      <td>\\r\\n                Phaa Rego pending - DECKAL...</td>\n",
              "      <td>value</td>\n",
              "      <td>16.0 hh</td>\n",
              "      <td>0 yrs</td>\n",
              "      <td>Buckskin</td>\n",
              "      <td>Colt</td>\n",
              "      <td>Paint Horse</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Beechwood, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 0  ONO</td>\n",
              "      <td>30-11-21-178636</td>\n",
              "      <td>4</td>\n",
              "      <td>/images/ResizedImages/30-11-21-296166Image1_w5...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>QL RIGHTON RINGER;WARRALEE APPLE DANISH</td>\n",
              "      <td>QL RIGHT ON THE MONEY;QUIRRAN LEA MISS GALAXY;...</td>\n",
              "      <td>STRAIT SMOKIN MONEY (IMP USA) 9047;QUIRRAN LEA...</td>\n",
              "      <td>paint-horse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/horses-for-sale/endurance-and-trail/Vee-Rock-...</td>\n",
              "      <td>\\r\\n                75 starts, $136,562 Prize ...</td>\n",
              "      <td>value</td>\n",
              "      <td>16.0 hh</td>\n",
              "      <td>12 yrs</td>\n",
              "      <td>Bay</td>\n",
              "      <td>Gelding</td>\n",
              "      <td>Standardbred</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Oaklands Junction, Victoria</td>\n",
              "      <td>Trade</td>\n",
              "      <td>$ 2500.00</td>\n",
              "      <td>30-11-21-497655</td>\n",
              "      <td>6</td>\n",
              "      <td>/images/ResizedImages/30-11-21-488434Image1_w5...</td>\n",
              "      <td></td>\n",
              "      <td>HERO__9-6-20-752499</td>\n",
              "      <td>;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>endurance-and-trail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/horses-for-sale/ponies/Tory__27-11-21-563432</td>\n",
              "      <td>\\r\\n                The most sweetest pony I h...</td>\n",
              "      <td>value</td>\n",
              "      <td>11.0 hh</td>\n",
              "      <td>10 yrs</td>\n",
              "      <td>Grey</td>\n",
              "      <td>Mare</td>\n",
              "      <td>Other</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Yamba, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 3500.00  ONO</td>\n",
              "      <td>27-11-21-563432</td>\n",
              "      <td>4</td>\n",
              "      <td>/images/ResizedImages/27-11-21-586832Image1_w5...</td>\n",
              "      <td>https://www.youtube.com/embed/lUedBJKyWAk</td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>ponies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/horses-for-sale/australian-stock-horse/Johnny...</td>\n",
              "      <td>\\r\\n                A real sweetheart who enjo...</td>\n",
              "      <td>value</td>\n",
              "      <td>14.3 hh</td>\n",
              "      <td>10 yrs</td>\n",
              "      <td>Bay</td>\n",
              "      <td>Gelding</td>\n",
              "      <td>Australian Stock Horse</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Yamba, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 4500.00  ONO</td>\n",
              "      <td>27-11-21-191667</td>\n",
              "      <td>4</td>\n",
              "      <td>/images/ResizedImages/27-11-21-562895Image1_w5...</td>\n",
              "      <td>https://www.youtube.com/embed/wIFXwr6xACE</td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>australian-stock-horse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/horses-for-sale/broodmare/Wanted---Riding-Pon...</td>\n",
              "      <td>\\r\\n                Looking for a registered r...</td>\n",
              "      <td>value</td>\n",
              "      <td>13.0 hh</td>\n",
              "      <td>7 yrs</td>\n",
              "      <td>Black</td>\n",
              "      <td>Mare</td>\n",
              "      <td>Riding Pony</td>\n",
              "      <td>Wanted</td>\n",
              "      <td>Currawang, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 500.00</td>\n",
              "      <td>24-11-21-697984</td>\n",
              "      <td>1</td>\n",
              "      <td>/images/ResizedImages/24-11-21-231789Image1_w5...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>broodmare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>/horses-for-sale/allrounder-pony/Tilly__16-12-...</td>\n",
              "      <td>\\r\\n                12 year old Australian sto...</td>\n",
              "      <td>value</td>\n",
              "      <td>12.0 hh</td>\n",
              "      <td>12 yrs</td>\n",
              "      <td>Brown</td>\n",
              "      <td>Mare</td>\n",
              "      <td>Australian Pony</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Mcgraths Hill, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 3500.00  Inc GST</td>\n",
              "      <td>16-12-19-224877</td>\n",
              "      <td>6</td>\n",
              "      <td>/images/ResizedImages/16-12-19-224877Image7_w5...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>allrounder-pony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>/horses-for-sale/allrounder-horse/Grey-TB-mare...</td>\n",
              "      <td>\\r\\n                Grey mare, 7 years old, st...</td>\n",
              "      <td>value</td>\n",
              "      <td>15.2 hh</td>\n",
              "      <td>7 yrs</td>\n",
              "      <td>Grey</td>\n",
              "      <td>Mare</td>\n",
              "      <td>Thoroughbred</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Geelong, Victoria</td>\n",
              "      <td>Private</td>\n",
              "      <td>POA</td>\n",
              "      <td>4-12-19-945675</td>\n",
              "      <td>1</td>\n",
              "      <td>/images/ResizedImages/4-12-19-248828Image1_w57...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>allrounder-horse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>/horses-for-sale/allrounder-pony/stunning-pony...</td>\n",
              "      <td>\\r\\n                Green broken Welsh B Pony....</td>\n",
              "      <td>value</td>\n",
              "      <td>12.2 hh</td>\n",
              "      <td>0 yrs</td>\n",
              "      <td>Black</td>\n",
              "      <td>Mare</td>\n",
              "      <td>Welsh Section B</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Drysdale, Victoria</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 5000.00  ONO</td>\n",
              "      <td>4-12-19-214163</td>\n",
              "      <td>1</td>\n",
              "      <td>/images/ResizedImages/4-12-19-214163Image3_w57...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>allrounder-pony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>/horses-for-sale/allrounder-pony/amazing-Bitle...</td>\n",
              "      <td>\\r\\n                This seven year old stocky...</td>\n",
              "      <td>value</td>\n",
              "      <td>14.0 hh</td>\n",
              "      <td>7 yrs</td>\n",
              "      <td>Buckskin</td>\n",
              "      <td>Mare</td>\n",
              "      <td>Other</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Bendigo South, Victoria</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 4500.00  Inc GST</td>\n",
              "      <td>3-12-19-282883</td>\n",
              "      <td>6</td>\n",
              "      <td>/images/ResizedImages/3-12-19-723137Image1_w57...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>allrounder-pony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>/horses-for-sale/allrounder-horse/Thoroughbred...</td>\n",
              "      <td>\\r\\n                For sale, due to no fault ...</td>\n",
              "      <td>value</td>\n",
              "      <td>17.1 hh</td>\n",
              "      <td>6 yrs</td>\n",
              "      <td>Bay</td>\n",
              "      <td>Gelding</td>\n",
              "      <td>Thoroughbred</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Kirton Point, South Australia</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 3500.00  ONO</td>\n",
              "      <td>1-12-19-628396</td>\n",
              "      <td>6</td>\n",
              "      <td>/images/ResizedImages/1-12-19-779872Image1_w57...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;</td>\n",
              "      <td>allrounder-horse</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              url_path  ...                category\n",
              "0    /horses-for-sale/paint-horse/Buckskin-Paint-Co...  ...             paint-horse\n",
              "1    /horses-for-sale/endurance-and-trail/Vee-Rock-...  ...     endurance-and-trail\n",
              "2        /horses-for-sale/ponies/Tory__27-11-21-563432  ...                  ponies\n",
              "3    /horses-for-sale/australian-stock-horse/Johnny...  ...  australian-stock-horse\n",
              "4    /horses-for-sale/broodmare/Wanted---Riding-Pon...  ...               broodmare\n",
              "..                                                 ...  ...                     ...\n",
              "165  /horses-for-sale/allrounder-pony/Tilly__16-12-...  ...         allrounder-pony\n",
              "166  /horses-for-sale/allrounder-horse/Grey-TB-mare...  ...        allrounder-horse\n",
              "167  /horses-for-sale/allrounder-pony/stunning-pony...  ...         allrounder-pony\n",
              "168  /horses-for-sale/allrounder-pony/amazing-Bitle...  ...         allrounder-pony\n",
              "169  /horses-for-sale/allrounder-horse/Thoroughbred...  ...        allrounder-horse\n",
              "\n",
              "[170 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "id": "Z8VhhpaojJFu",
        "outputId": "00b90b3c-cb9f-4137-c81c-ce19d7d2bd3f"
      },
      "source": [
        "df_tophorse_item_details[df_tophorse_item_details['parents'] != \";\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url_path</th>\n",
              "      <th>Description</th>\n",
              "      <th>index</th>\n",
              "      <th>Height</th>\n",
              "      <th>Age</th>\n",
              "      <th>Colour</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Breed</th>\n",
              "      <th>Terms</th>\n",
              "      <th>Location</th>\n",
              "      <th>P/Trade</th>\n",
              "      <th>Price</th>\n",
              "      <th>Ad Code</th>\n",
              "      <th>image_count</th>\n",
              "      <th>main_image_url_path</th>\n",
              "      <th>video_url</th>\n",
              "      <th>Seller_Id</th>\n",
              "      <th>parents</th>\n",
              "      <th>grand_parents</th>\n",
              "      <th>great_grand_parents</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/horses-for-sale/paint-horse/Buckskin-Paint-Co...</td>\n",
              "      <td>\\r\\n                Phaa Rego pending - DECKAL...</td>\n",
              "      <td>value</td>\n",
              "      <td>16.0 hh</td>\n",
              "      <td>0 yrs</td>\n",
              "      <td>Buckskin</td>\n",
              "      <td>Colt</td>\n",
              "      <td>Paint Horse</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Beechwood, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 0  ONO</td>\n",
              "      <td>30-11-21-178636</td>\n",
              "      <td>4</td>\n",
              "      <td>/images/ResizedImages/30-11-21-296166Image1_w5...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>QL RIGHTON RINGER;WARRALEE APPLE DANISH</td>\n",
              "      <td>QL RIGHT ON THE MONEY;QUIRRAN LEA MISS GALAXY;...</td>\n",
              "      <td>STRAIT SMOKIN MONEY (IMP USA) 9047;QUIRRAN LEA...</td>\n",
              "      <td>paint-horse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/horses-for-sale/allrounder-horse/Sophie__25-1...</td>\n",
              "      <td>\\r\\n                Racename: Mamzelle Sophie\\...</td>\n",
              "      <td>value</td>\n",
              "      <td>16.1 hh</td>\n",
              "      <td>6 yrs</td>\n",
              "      <td>Chestnut</td>\n",
              "      <td>Mare</td>\n",
              "      <td>Thoroughbred</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Barnawartha, Victoria</td>\n",
              "      <td>Private</td>\n",
              "      <td>POA</td>\n",
              "      <td>25-11-21-919693</td>\n",
              "      <td>3</td>\n",
              "      <td>/images/ResizedImages/25-11-21-896767Image46_w...</td>\n",
              "      <td></td>\n",
              "      <td>JW-Equestrian__24-6-21-819416</td>\n",
              "      <td>Choisir;Sophielicious</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;;;;;</td>\n",
              "      <td>allrounder-horse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/horses-for-sale/allrounder-horse/Manny__25-11...</td>\n",
              "      <td>\\r\\n                Racename: All Starr Courag...</td>\n",
              "      <td>value</td>\n",
              "      <td>16.1 hh</td>\n",
              "      <td>7 yrs</td>\n",
              "      <td>Chestnut</td>\n",
              "      <td>Gelding</td>\n",
              "      <td>Thoroughbred</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Barnawartha, Victoria</td>\n",
              "      <td>Private</td>\n",
              "      <td>POA</td>\n",
              "      <td>25-11-21-149549</td>\n",
              "      <td>6</td>\n",
              "      <td>/images/ResizedImages/25-11-21-318156Image41_w...</td>\n",
              "      <td></td>\n",
              "      <td>JW-Equestrian__24-6-21-819416</td>\n",
              "      <td>Strategic Maneuver;Caseys Courage</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;;;;;</td>\n",
              "      <td>allrounder-horse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/horses-for-sale/allrounder-horse/Alex__25-11-...</td>\n",
              "      <td>\\r\\n                Racename: Ajyaal\\r DOB: 13...</td>\n",
              "      <td>value</td>\n",
              "      <td>16.2 hh</td>\n",
              "      <td>5 yrs</td>\n",
              "      <td>Bay</td>\n",
              "      <td>Gelding</td>\n",
              "      <td>Thoroughbred</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Barnawartha, Victoria</td>\n",
              "      <td>Private</td>\n",
              "      <td>POA</td>\n",
              "      <td>25-11-21-227556</td>\n",
              "      <td>6</td>\n",
              "      <td>/images/ResizedImages/25-11-21-256712Image36_w...</td>\n",
              "      <td></td>\n",
              "      <td>JW-Equestrian__24-6-21-819416</td>\n",
              "      <td>Deep Field;Albakoor</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;;;;;</td>\n",
              "      <td>allrounder-horse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/horses-for-sale/allrounder-horse/Prince__25-1...</td>\n",
              "      <td>\\r\\n                Price enjoys going slow, t...</td>\n",
              "      <td>value</td>\n",
              "      <td>16.0 hh</td>\n",
              "      <td>4 yrs</td>\n",
              "      <td>Chestnut</td>\n",
              "      <td>Gelding</td>\n",
              "      <td>Thoroughbred</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Barnawartha, Victoria</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 2500.00</td>\n",
              "      <td>25-11-21-732997</td>\n",
              "      <td>6</td>\n",
              "      <td>/images/ResizedImages/25-11-21-682328Image31_w...</td>\n",
              "      <td></td>\n",
              "      <td>JW-Equestrian__24-6-21-819416</td>\n",
              "      <td>Snitzle;Star Of Sydney</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;;;;;</td>\n",
              "      <td>allrounder-horse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>/horses-for-sale/mountain-and-moorland/BAMBORO...</td>\n",
              "      <td>\\r\\n                Welsh Mountain Pony\\r Grey...</td>\n",
              "      <td>value</td>\n",
              "      <td>11.1 hh</td>\n",
              "      <td>1 yrs</td>\n",
              "      <td>Grey</td>\n",
              "      <td>Gelding</td>\n",
              "      <td>Other</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Cowra, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>POA</td>\n",
              "      <td>5-3-20-363618</td>\n",
              "      <td>3</td>\n",
              "      <td>/images/ResizedImages/5-3-20-811358Image1_w577...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Llangollen Top of the Pops;Bamborough Pou Pi Du</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;;;;;</td>\n",
              "      <td>mountain-and-moorland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>/horses-for-sale/performance-pony/Quality-Part...</td>\n",
              "      <td>\\r\\n                BAMBOROUGH GOSPEL\\r DOB: 2...</td>\n",
              "      <td>value</td>\n",
              "      <td>13.1 hh</td>\n",
              "      <td>7 yrs</td>\n",
              "      <td>Chestnut</td>\n",
              "      <td>Filly</td>\n",
              "      <td>Other</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Cowra, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>POA</td>\n",
              "      <td>5-3-20-312285</td>\n",
              "      <td>1</td>\n",
              "      <td>/images/ResizedImages/5-3-20-312285Image1_w577...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Rathowen Paragon;Bamborough Graceful</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;;;;;</td>\n",
              "      <td>performance-pony</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>/horses-for-sale/broodmare/Bamborough-Royal-Me...</td>\n",
              "      <td>\\r\\n                DOB: 25.11.08\\r Lovely bro...</td>\n",
              "      <td>value</td>\n",
              "      <td>13.0 hh</td>\n",
              "      <td>12 yrs</td>\n",
              "      <td>Chestnut</td>\n",
              "      <td>Mare</td>\n",
              "      <td>Other</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Cowra, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>POA</td>\n",
              "      <td>5-3-20-727149</td>\n",
              "      <td>1</td>\n",
              "      <td>/images/ResizedImages/5-3-20-525165Image6_w577...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Naruni Park Taylor Made;Bamborough Royal Rhapsody</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;;;;;</td>\n",
              "      <td>broodmare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>/horses-for-sale/broodmare/Lovely-Part-Welsh-B...</td>\n",
              "      <td>\\r\\n                SILKWOOD SUPERNATURAL\\r DO...</td>\n",
              "      <td>value</td>\n",
              "      <td>14.1 hh</td>\n",
              "      <td>14 yrs</td>\n",
              "      <td>Chestnut</td>\n",
              "      <td>Mare</td>\n",
              "      <td>Other</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Cowra, New South Wales</td>\n",
              "      <td>Private</td>\n",
              "      <td>POA</td>\n",
              "      <td>5-3-20-953732</td>\n",
              "      <td>1</td>\n",
              "      <td>/images/ResizedImages/5-3-20-312145Image7_w577...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Silkwood Puss N Boots;Silkwood Sweet Charity</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;;;;;</td>\n",
              "      <td>broodmare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>/horses-for-sale/racing/Pluck-Colt__9-2-20-699229</td>\n",
              "      <td>\\r\\n                Two year old Pluck colt, o...</td>\n",
              "      <td>value</td>\n",
              "      <td>15.0 hh</td>\n",
              "      <td>2 yrs</td>\n",
              "      <td>Dark Bay</td>\n",
              "      <td>Colt</td>\n",
              "      <td>Thoroughbred</td>\n",
              "      <td>For Sale</td>\n",
              "      <td>Camp Mountain, Queensland</td>\n",
              "      <td>Private</td>\n",
              "      <td>$ 4999.00</td>\n",
              "      <td>9-2-20-699229</td>\n",
              "      <td>1</td>\n",
              "      <td>/images/ResizedImages/9-2-20-699229Image1_w577...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Pluck;Miss Aviatrix</td>\n",
              "      <td>;;;</td>\n",
              "      <td>;;;;;;;</td>\n",
              "      <td>racing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>78 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              url_path  ...               category\n",
              "0    /horses-for-sale/paint-horse/Buckskin-Paint-Co...  ...            paint-horse\n",
              "5    /horses-for-sale/allrounder-horse/Sophie__25-1...  ...       allrounder-horse\n",
              "6    /horses-for-sale/allrounder-horse/Manny__25-11...  ...       allrounder-horse\n",
              "7    /horses-for-sale/allrounder-horse/Alex__25-11-...  ...       allrounder-horse\n",
              "8    /horses-for-sale/allrounder-horse/Prince__25-1...  ...       allrounder-horse\n",
              "..                                                 ...  ...                    ...\n",
              "150  /horses-for-sale/mountain-and-moorland/BAMBORO...  ...  mountain-and-moorland\n",
              "151  /horses-for-sale/performance-pony/Quality-Part...  ...       performance-pony\n",
              "152  /horses-for-sale/broodmare/Bamborough-Royal-Me...  ...              broodmare\n",
              "153  /horses-for-sale/broodmare/Lovely-Part-Welsh-B...  ...              broodmare\n",
              "157  /horses-for-sale/racing/Pluck-Colt__9-2-20-699229  ...                 racing\n",
              "\n",
              "[78 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx_4bnfqCN2H"
      },
      "source": [
        "## horseforum-health"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlQWnn9LHNGL"
      },
      "source": [
        "### UDF scrape forum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYGPkAK8HHIr"
      },
      "source": [
        "def get_next_page_url_horseforum(horseforum_soup):\n",
        "    \"\"\"\n",
        "    Gets the 'next page' url path from the www.horseforum.com forum page.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : horseforum_soup\n",
        "        A BeautifulSoup object for the web page.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        the relative url path for the 'next page' if successful, otherwise an empty string.\n",
        "    \"\"\"\n",
        "    soup = horseforum_soup\n",
        "    url_path = \"\"\n",
        "    try:\n",
        "        url_path = soup.find('a', { \"aria-label\" : \"Next Page\" })['href']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return url_path\n",
        "\n",
        "\n",
        "\n",
        "def get_threads_horseforum(horseforum_soup):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : horseforum_soup\n",
        "        A BeautifulSoup object for the web page.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    bs4.element.ResultSet\n",
        "        An iterable collection of advert listings, as returned by BeautifulSoup\n",
        "    \"\"\"\n",
        "    soup = horseforum_soup\n",
        "    return soup.find_all('div', class_=\"california-thread-item\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def scrape_thread_details_horseforum(forum_listings):\n",
        "    \"\"\"\n",
        "    Iterates a bs4 ResultSet of horse forum (i.e., https://www.horseforum.com/forums/horse-health.17/)\n",
        "    listings to get predefined values.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.element.ResultSet : forum_listings\n",
        "        An iterable collection of forum listings, as returned by BeautifulSoup\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    list of dict {str, Any}\n",
        "        the predefined details of each forum-post:\n",
        "            + item_title\n",
        "            + item_url_path\n",
        "            + item_created_date\n",
        "            + item_created_by\n",
        "            + item_created_by_url_path\n",
        "            + item_view_count\n",
        "            + item_reply_count\n",
        "            + item_last_replied_date\n",
        "            + item_last_replied_by\n",
        "            + item_last_replied_by_url_path\n",
        "\n",
        "    \"\"\"\n",
        "    listings = forum_listings\n",
        "    data_items=[]\n",
        "    if listings is not None:\n",
        "        for item in listings:\n",
        "            # initialise\n",
        "            item_title = \"\"\n",
        "            item_url_path = \"\"\n",
        "            item_created_date = \"\"\n",
        "            item_created_by = \"\"\n",
        "            item_created_by_url_path = \"\"\n",
        "            item_view_count = \"\"\n",
        "            item_reply_count = \"\"\n",
        "            item_last_replied_date = \"\"\n",
        "            item_last_replied_by = \"\"\n",
        "            item_last_replied_by_url_path = \"\"\n",
        "\n",
        "            # Get item's listing title and details URL\n",
        "            try:\n",
        "                tag = item.find('div', class_=\"structItem-title\").find('a', { 'qid' : \"thread-item-title\"})\n",
        "                item_title = tag.get_text()\n",
        "                item_url_path = tag['href']\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Get item's created date\n",
        "            try:\n",
        "                item_created_date = item.find(\n",
        "                    'div', class_=\"structItem-minor\"\n",
        "                    ).find('a', { 'qid' : \"thread-item-start-date\"}).find('time')['datetime']\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Get item's created by\n",
        "            try:\n",
        "                tag = item.find(class_=\"structItem-username\").find('a', class_=\"username\")\n",
        "                item_created_by = tag.get_text()\n",
        "                item_created_by_url_path = tag['href']\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Get item's view count\n",
        "            try:\n",
        "                item_view_count = item.find('div', class_=\"view-count\").find('span')['title']\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Get item's reply count\n",
        "            try:\n",
        "                item_reply_count = item.find('div', class_=\"reply-count\").find('span').get_text()\n",
        "            except:\n",
        "                pass            \n",
        "\n",
        "            # Get item's last replied date\n",
        "            try:\n",
        "                item_last_replied_date = item.find('div', class_=\"last-poster\").find('time')['datetime']\n",
        "            except:\n",
        "                pass            \n",
        "\n",
        "            # Get item's last replied by\n",
        "            try:\n",
        "                tag = item.find('div', class_=\"last-poster\").find('a', class_=\"username\")\n",
        "                item_last_replied_by = tag.get_text()\n",
        "                item_last_replied_by_url_path = tag['href']\n",
        "            except:\n",
        "                pass            \n",
        "\n",
        "            # Save result\n",
        "            dict_item = {\n",
        "                'item_title' : item_title\n",
        "                ,'item_url_path' : item_url_path\n",
        "                ,'item_created_date' : item_created_date\n",
        "                ,'item_created_by' : item_created_by\n",
        "                ,'item_created_by_url_path' : item_created_by_url_path\n",
        "                ,'item_view_count' : item_view_count\n",
        "                ,'item_reply_count' : item_reply_count\n",
        "                ,'item_last_replied_date' : item_last_replied_date\n",
        "                ,'item_last_replied_by' : item_last_replied_by\n",
        "                ,'item_last_replied_by_url_path' : item_last_replied_by_url_path\n",
        "                }\n",
        "\n",
        "            data_items.append(dict_item.copy())\n",
        "\n",
        "    return data_items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApBqnLH0fezF"
      },
      "source": [
        "### Crawl horseforum - health"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewdNiHSPfnAh",
        "outputId": "921b0611-3920-4287-da84-831e54efe5d9"
      },
      "source": [
        "# Specify which web page should be crawled\n",
        "url_domain =  \"https://www.horseforum.com\"\n",
        "url_path = \"/forums/horse-health.17/\" # note terminating '/'\n",
        "\n",
        "# Set functions relevant to scraping the web page\n",
        "get_ResultSet = get_threads_horseforum\n",
        "get_ResultSet_data = scrape_thread_details_horseforum\n",
        "get_next_page_url = get_next_page_url_horseforum\n",
        "\n",
        "# Crawl pages and scrape\n",
        "start_time = time()\n",
        "print('Crawl start UTC: {}'.format(datetime.fromtimestamp(start_time)))\n",
        "data_horseforum_threads, _ = web_crawler(\n",
        "    url_domain =  url_domain\n",
        "    ,url_path = url_path\n",
        "    ,fx_get_ResultSet = get_ResultSet\n",
        "    ,fx_get_ResultSet_data = get_ResultSet_data\n",
        "    ,fx_get_next_page_url = get_next_page_url    \n",
        "    #,max_pages = 2\n",
        "    ,echo_every_n = 25\n",
        ")\n",
        "end_time = time()\n",
        "print(\"---crawl complete---\")\n",
        "print()\n",
        "print(\"Thread count: {}\".format(len(data_horseforum_threads)))\n",
        "print(\"Crawl time (sec): {0}\".format(end_time - start_time))\n",
        "print('Crawl end UTC: {}'.format(datetime.fromtimestamp(end_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crawl start UTC: 2021-11-30 13:28:37.212199\n",
            "Page 25, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 50, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 75, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 100, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 125, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 150, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 175, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 200, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 225, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 250, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 275, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 300, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 325, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 350, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 375, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 400, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 425, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 450, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 475, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 500, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 525, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 550, HTTP response status: 200\n",
            "\t35 items...\n",
            "Page 575, HTTP response status: 200\n",
            "\t35 items...\n",
            "---crawl complete---\n",
            "\n",
            "Thread count: 20954\n",
            "Crawl time (sec): 408.14657640457153\n",
            "Crawl end UTC: 2021-11-30 13:35:25.358776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "uuBtCnZRkKDo",
        "outputId": "53eaa5e7-ff80-450f-ba14-642d3ec54d22"
      },
      "source": [
        "# Convert to data frame and save result locally\n",
        "df_horseforum_threads = pd.DataFrame(data_horseforum_threads)\n",
        "\n",
        "# Save dataframe locally\n",
        "df_horseforum_threads.to_csv(os.path.join(filepath_data, filename_horseforum_threads_df), index=False)\n",
        "\n",
        "df_horseforum_threads"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_title</th>\n",
              "      <th>item_url_path</th>\n",
              "      <th>item_created_date</th>\n",
              "      <th>item_created_by</th>\n",
              "      <th>item_created_by_url_path</th>\n",
              "      <th>item_view_count</th>\n",
              "      <th>item_reply_count</th>\n",
              "      <th>item_last_replied_date</th>\n",
              "      <th>item_last_replied_by</th>\n",
              "      <th>item_last_replied_by_url_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PLEASE READ BEFORE POSTING (both older and new...</td>\n",
              "      <td>/threads/please-read-before-posting-both-older...</td>\n",
              "      <td>2020-12-27T19:19:33-0500</td>\n",
              "      <td>TaMMa89</td>\n",
              "      <td>/members/tamma89.3542/</td>\n",
              "      <td>1076</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-12-27T19:19:33-0500</td>\n",
              "      <td>TaMMa89</td>\n",
              "      <td>/members/tamma89.3542/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>poisonous plants from HF member locations</td>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>2018-01-01T22:03:05-0500</td>\n",
              "      <td>Smilie</td>\n",
              "      <td>/members/smilie.18361/</td>\n",
              "      <td>2151</td>\n",
              "      <td>5</td>\n",
              "      <td>2020-12-08T16:29:12-0500</td>\n",
              "      <td>stevenson</td>\n",
              "      <td>/members/stevenson.26572/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Care of an Emaciated Horse</td>\n",
              "      <td>/threads/the-care-of-an-emaciated-horse.100412/</td>\n",
              "      <td>2011-10-14T09:02:04-0400</td>\n",
              "      <td>xxBarry Godden</td>\n",
              "      <td>/members/xxbarry-godden.9451/</td>\n",
              "      <td>48970</td>\n",
              "      <td>54</td>\n",
              "      <td>2020-11-26T10:09:30-0500</td>\n",
              "      <td>horselovinguy</td>\n",
              "      <td>/members/horselovinguy.79162/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Making a Vet Kit</td>\n",
              "      <td>/threads/making-a-vet-kit.251/</td>\n",
              "      <td>2007-01-07T02:14:09-0500</td>\n",
              "      <td>Skippy!</td>\n",
              "      <td>/members/skippy.157/</td>\n",
              "      <td>2091441</td>\n",
              "      <td>277</td>\n",
              "      <td>2019-08-26T04:44:59-0400</td>\n",
              "      <td>AmiraAchek</td>\n",
              "      <td>/members/amiraachek.280747/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Information on Myopathies - PSSM1, PSSM2, MFM,...</td>\n",
              "      <td>/threads/information-on-myopathies-pssm1-pssm2...</td>\n",
              "      <td>2017-08-17T20:06:14-0400</td>\n",
              "      <td>Espy</td>\n",
              "      <td>/members/espy.168162/</td>\n",
              "      <td>17546</td>\n",
              "      <td>5</td>\n",
              "      <td>2018-09-17T16:44:33-0400</td>\n",
              "      <td>Espy</td>\n",
              "      <td>/members/espy.168162/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20949</th>\n",
              "      <td>Recovery from Torn Rear Suspensory Ligament</td>\n",
              "      <td>/threads/recovery-from-torn-rear-suspensory-li...</td>\n",
              "      <td>2006-12-22T05:26:11-0500</td>\n",
              "      <td>trusspt</td>\n",
              "      <td>/members/trusspt.170/</td>\n",
              "      <td>6106</td>\n",
              "      <td>1</td>\n",
              "      <td>2006-12-30T04:51:20-0500</td>\n",
              "      <td>stacyh</td>\n",
              "      <td>/members/stacyh.186/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20950</th>\n",
              "      <td>how to get horses to gaine weight</td>\n",
              "      <td>/threads/how-to-get-horses-to-gaine-weight.99/</td>\n",
              "      <td>2006-12-05T11:54:51-0500</td>\n",
              "      <td>nybarrelracer</td>\n",
              "      <td>/members/nybarrelracer.121/</td>\n",
              "      <td>4988</td>\n",
              "      <td>14</td>\n",
              "      <td>2006-12-21T07:55:03-0500</td>\n",
              "      <td>brandig</td>\n",
              "      <td>/members/brandig.57/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20951</th>\n",
              "      <td>PAXIL?</td>\n",
              "      <td>/threads/paxil.102/</td>\n",
              "      <td>2006-12-06T10:09:20-0500</td>\n",
              "      <td>tuffstuff</td>\n",
              "      <td>/members/tuffstuff.123/</td>\n",
              "      <td>3240</td>\n",
              "      <td>3</td>\n",
              "      <td>2006-12-11T20:29:12-0500</td>\n",
              "      <td>kristy</td>\n",
              "      <td>/members/kristy.132/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20952</th>\n",
              "      <td>Loose stool</td>\n",
              "      <td>/threads/loose-stool.101/</td>\n",
              "      <td>2006-12-05T18:42:31-0500</td>\n",
              "      <td>Cedarsgirl</td>\n",
              "      <td>/members/cedarsgirl.120/</td>\n",
              "      <td>5694</td>\n",
              "      <td>10</td>\n",
              "      <td>2006-12-10T21:52:11-0500</td>\n",
              "      <td>Cedarsgirl</td>\n",
              "      <td>/members/cedarsgirl.120/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20953</th>\n",
              "      <td>Quietex</td>\n",
              "      <td>/threads/quietex.49/</td>\n",
              "      <td>2006-11-14T23:17:30-0500</td>\n",
              "      <td>KristyMarie87</td>\n",
              "      <td>/members/kristymarie87.65/</td>\n",
              "      <td>5970</td>\n",
              "      <td>2</td>\n",
              "      <td>2006-11-20T11:19:12-0500</td>\n",
              "      <td>OhSnapItsRoxy</td>\n",
              "      <td>/members/ohsnapitsroxy.77/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20954 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              item_title  ...  item_last_replied_by_url_path\n",
              "0      PLEASE READ BEFORE POSTING (both older and new...  ...         /members/tamma89.3542/\n",
              "1              poisonous plants from HF member locations  ...      /members/stevenson.26572/\n",
              "2                         The Care of an Emaciated Horse  ...  /members/horselovinguy.79162/\n",
              "3                                       Making a Vet Kit  ...    /members/amiraachek.280747/\n",
              "4      Information on Myopathies - PSSM1, PSSM2, MFM,...  ...          /members/espy.168162/\n",
              "...                                                  ...  ...                            ...\n",
              "20949        Recovery from Torn Rear Suspensory Ligament  ...           /members/stacyh.186/\n",
              "20950                  how to get horses to gaine weight  ...           /members/brandig.57/\n",
              "20951                                             PAXIL?  ...           /members/kristy.132/\n",
              "20952                                        Loose stool  ...       /members/cedarsgirl.120/\n",
              "20953                                            Quietex  ...     /members/ohsnapitsroxy.77/\n",
              "\n",
              "[20954 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HS02wtyEIdg"
      },
      "source": [
        "### Reload previous crawl: horseforum threads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "88XuAV39ENMl",
        "outputId": "4d3632d7-50d7-417f-a3fa-59f2f92bb01b"
      },
      "source": [
        "# Reload  horseforum threads\n",
        "df_horseforum_threads = pd.read_csv(os.path.join(filepath_data, filename_horseforum_threads_df))\n",
        "df_horseforum_threads"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_title</th>\n",
              "      <th>item_url_path</th>\n",
              "      <th>item_created_date</th>\n",
              "      <th>item_created_by</th>\n",
              "      <th>item_created_by_url_path</th>\n",
              "      <th>item_view_count</th>\n",
              "      <th>item_reply_count</th>\n",
              "      <th>item_last_replied_date</th>\n",
              "      <th>item_last_replied_by</th>\n",
              "      <th>item_last_replied_by_url_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PLEASE READ BEFORE POSTING (both older and new...</td>\n",
              "      <td>/threads/please-read-before-posting-both-older...</td>\n",
              "      <td>2020-12-27T19:19:33-0500</td>\n",
              "      <td>TaMMa89</td>\n",
              "      <td>/members/tamma89.3542/</td>\n",
              "      <td>1076</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-12-27T19:19:33-0500</td>\n",
              "      <td>TaMMa89</td>\n",
              "      <td>/members/tamma89.3542/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>poisonous plants from HF member locations</td>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>2018-01-01T22:03:05-0500</td>\n",
              "      <td>Smilie</td>\n",
              "      <td>/members/smilie.18361/</td>\n",
              "      <td>2151</td>\n",
              "      <td>5</td>\n",
              "      <td>2020-12-08T16:29:12-0500</td>\n",
              "      <td>stevenson</td>\n",
              "      <td>/members/stevenson.26572/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Care of an Emaciated Horse</td>\n",
              "      <td>/threads/the-care-of-an-emaciated-horse.100412/</td>\n",
              "      <td>2011-10-14T09:02:04-0400</td>\n",
              "      <td>xxBarry Godden</td>\n",
              "      <td>/members/xxbarry-godden.9451/</td>\n",
              "      <td>48970</td>\n",
              "      <td>54</td>\n",
              "      <td>2020-11-26T10:09:30-0500</td>\n",
              "      <td>horselovinguy</td>\n",
              "      <td>/members/horselovinguy.79162/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Making a Vet Kit</td>\n",
              "      <td>/threads/making-a-vet-kit.251/</td>\n",
              "      <td>2007-01-07T02:14:09-0500</td>\n",
              "      <td>Skippy!</td>\n",
              "      <td>/members/skippy.157/</td>\n",
              "      <td>2091441</td>\n",
              "      <td>277</td>\n",
              "      <td>2019-08-26T04:44:59-0400</td>\n",
              "      <td>AmiraAchek</td>\n",
              "      <td>/members/amiraachek.280747/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Information on Myopathies - PSSM1, PSSM2, MFM,...</td>\n",
              "      <td>/threads/information-on-myopathies-pssm1-pssm2...</td>\n",
              "      <td>2017-08-17T20:06:14-0400</td>\n",
              "      <td>Espy</td>\n",
              "      <td>/members/espy.168162/</td>\n",
              "      <td>17546</td>\n",
              "      <td>5</td>\n",
              "      <td>2018-09-17T16:44:33-0400</td>\n",
              "      <td>Espy</td>\n",
              "      <td>/members/espy.168162/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20949</th>\n",
              "      <td>Recovery from Torn Rear Suspensory Ligament</td>\n",
              "      <td>/threads/recovery-from-torn-rear-suspensory-li...</td>\n",
              "      <td>2006-12-22T05:26:11-0500</td>\n",
              "      <td>trusspt</td>\n",
              "      <td>/members/trusspt.170/</td>\n",
              "      <td>6106</td>\n",
              "      <td>1</td>\n",
              "      <td>2006-12-30T04:51:20-0500</td>\n",
              "      <td>stacyh</td>\n",
              "      <td>/members/stacyh.186/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20950</th>\n",
              "      <td>how to get horses to gaine weight</td>\n",
              "      <td>/threads/how-to-get-horses-to-gaine-weight.99/</td>\n",
              "      <td>2006-12-05T11:54:51-0500</td>\n",
              "      <td>nybarrelracer</td>\n",
              "      <td>/members/nybarrelracer.121/</td>\n",
              "      <td>4988</td>\n",
              "      <td>14</td>\n",
              "      <td>2006-12-21T07:55:03-0500</td>\n",
              "      <td>brandig</td>\n",
              "      <td>/members/brandig.57/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20951</th>\n",
              "      <td>PAXIL?</td>\n",
              "      <td>/threads/paxil.102/</td>\n",
              "      <td>2006-12-06T10:09:20-0500</td>\n",
              "      <td>tuffstuff</td>\n",
              "      <td>/members/tuffstuff.123/</td>\n",
              "      <td>3240</td>\n",
              "      <td>3</td>\n",
              "      <td>2006-12-11T20:29:12-0500</td>\n",
              "      <td>kristy</td>\n",
              "      <td>/members/kristy.132/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20952</th>\n",
              "      <td>Loose stool</td>\n",
              "      <td>/threads/loose-stool.101/</td>\n",
              "      <td>2006-12-05T18:42:31-0500</td>\n",
              "      <td>Cedarsgirl</td>\n",
              "      <td>/members/cedarsgirl.120/</td>\n",
              "      <td>5694</td>\n",
              "      <td>10</td>\n",
              "      <td>2006-12-10T21:52:11-0500</td>\n",
              "      <td>Cedarsgirl</td>\n",
              "      <td>/members/cedarsgirl.120/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20953</th>\n",
              "      <td>Quietex</td>\n",
              "      <td>/threads/quietex.49/</td>\n",
              "      <td>2006-11-14T23:17:30-0500</td>\n",
              "      <td>KristyMarie87</td>\n",
              "      <td>/members/kristymarie87.65/</td>\n",
              "      <td>5970</td>\n",
              "      <td>2</td>\n",
              "      <td>2006-11-20T11:19:12-0500</td>\n",
              "      <td>OhSnapItsRoxy</td>\n",
              "      <td>/members/ohsnapitsroxy.77/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20954 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              item_title  ...  item_last_replied_by_url_path\n",
              "0      PLEASE READ BEFORE POSTING (both older and new...  ...         /members/tamma89.3542/\n",
              "1              poisonous plants from HF member locations  ...      /members/stevenson.26572/\n",
              "2                         The Care of an Emaciated Horse  ...  /members/horselovinguy.79162/\n",
              "3                                       Making a Vet Kit  ...    /members/amiraachek.280747/\n",
              "4      Information on Myopathies - PSSM1, PSSM2, MFM,...  ...          /members/espy.168162/\n",
              "...                                                  ...  ...                            ...\n",
              "20949        Recovery from Torn Rear Suspensory Ligament  ...           /members/stacyh.186/\n",
              "20950                  how to get horses to gaine weight  ...           /members/brandig.57/\n",
              "20951                                             PAXIL?  ...           /members/kristy.132/\n",
              "20952                                        Loose stool  ...       /members/cedarsgirl.120/\n",
              "20953                                            Quietex  ...     /members/ohsnapitsroxy.77/\n",
              "\n",
              "[20954 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBD-BR9Iez8s"
      },
      "source": [
        "### UDF scrape thread"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anSMXuWge4Kd"
      },
      "source": [
        "def get_horseforum_thread_participant_count(horseforum_soup):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : horseforum_soup\n",
        "        A BeautifulSoup object for the web page, being a 'page' of a 'thread'\n",
        "        on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    int\n",
        "        the number of users who have posted against the thread, otherwise np.nan.\n",
        "    \"\"\"\n",
        "    soup = horseforum_soup\n",
        "    participant_count = np.nan\n",
        "    try:\n",
        "        participant_count = soup.find(\n",
        "            'div', class_=\"stats-container\"\n",
        "            ).find('span', { 'qid' : 'thread-about-discussion-participant-count' }).get_text()\n",
        "        participant_count = int(participant_count)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return participant_count\n",
        "\n",
        "\n",
        "\n",
        "def scrape_thread_page_details_horseforum(horseforum_soup):\n",
        "    \"\"\"\n",
        "    Iterates a bs4 ResultSet of a horse forum thread (i.e., https://www.horseforum.com/forums/horse-health.17/)\n",
        "    listings to get predefined values.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : horseforum_soup\n",
        "        A BeautifulSoup object for the web page, being the first 'page'\n",
        "        of posts for a 'thread' on the forum.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict {str, Any}\n",
        "        the predefined details of a thread's page:\n",
        "            + participant_count\n",
        "\n",
        "    \"\"\"\n",
        "    soup = horseforum_soup\n",
        "    participant_count = get_horseforum_thread_participant_count(soup)\n",
        "\n",
        "    # Save result\n",
        "    dict_page = {\n",
        "        'participant_count' : participant_count\n",
        "        }\n",
        "       \n",
        "    return dict_page\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_horseforum_thread_page_next(horseforum_soup):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : horseforum_soup\n",
        "        A BeautifulSoup object for the web page, being a 'page' of posts for \n",
        "        a 'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        the relative url path for the 'next page' if successful, otherwise an empty string.\n",
        "    \"\"\"\n",
        "    soup = horseforum_soup\n",
        "    url_path = \"\"\n",
        "    try:\n",
        "        url_path = soup.find('a', { 'qid' : 'page-nav-next-button'})['href']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return url_path\n",
        "\n",
        "\n",
        "def get_horseforum_thread_page_last(horseforum_soup):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : horseforum_soup\n",
        "        A BeautifulSoup object for the web page, being a 'page' of posts for \n",
        "        a 'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        the relative url path for the 'last page' if successful, otherwise an empty string.\n",
        "    \"\"\"\n",
        "    soup = horseforum_soup\n",
        "    url_path = \"\"\n",
        "    try:\n",
        "        url_path = soup.find('a', { 'qid' : \"thread-jump-to-latest\"})['href']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return url_path\n",
        "\n",
        "\n",
        "\n",
        "def get_horseforum_thread_page_posts(horseforum_soup):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : horseforum_soup\n",
        "        A BeautifulSoup object for the web page.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    bs4.element.ResultSet\n",
        "        An iterable collection of posts (for the thread on the current page), \n",
        "        as returned by BeautifulSoup.\n",
        "    \"\"\"\n",
        "    soup = horseforum_soup\n",
        "    post_items = None\n",
        "    try:\n",
        "        post_items = soup.find('div', { 'qid' : 'thread-box-parent'}).find_all('article', { 'qid' : 'post-item'})\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_items\n",
        "\n",
        "\n",
        "\n",
        "def scrape_thread_post_details_horseforum(page_posts, url_domain):\n",
        "    \"\"\"\n",
        "    Iterates a bs4 ResultSet of a horse forum thread (i.e., https://www.horseforum.com/forums/horse-health.17/)\n",
        "    listings to get predefined values.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.element.ResultSet : page_posts\n",
        "        An iterable collection of forum listings, as returned by BeautifulSoup\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    list of dict {str, Any}\n",
        "        the predefined details of each forum-post:\n",
        "            + item_title\n",
        "            + item_url_path\n",
        "            + item_created_date\n",
        "            + item_created_by\n",
        "            + item_created_by_url_path\n",
        "            + item_view_count\n",
        "            + item_reply_count\n",
        "            + item_last_replied_date\n",
        "            + item_last_replied_by\n",
        "            + item_last_replied_by_url_path\n",
        "\n",
        "    \"\"\"\n",
        "    listings = page_posts\n",
        "    data_items=[]\n",
        "    if listings is not None:\n",
        "        for item in listings:   \n",
        "            # Get result\n",
        "            dict_item = scrape_horseforum_post(item, url_domain)\n",
        "\n",
        "            data_items.append(dict_item.copy())\n",
        "\n",
        "    return data_items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd7FbfwDTeLP"
      },
      "source": [
        "### UDF scrape post"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNfj8hWZS0J_"
      },
      "source": [
        "def get_horseforum_post_id(post):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        The identifier for the post, if successful, otherwise \"\"\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_id = \"\"\n",
        "    try:\n",
        "        post_id = post['data-content']\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_id\n",
        "\n",
        "\n",
        "def get_horseforum_post_number(post):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    int\n",
        "        The post number (relative to the thread), if successful, otherwise np.nan\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_number = np.nan\n",
        "    try:\n",
        "        post_number = post.find('a', { 'qid' : \"post-number\"}).get_text()\n",
        "        post_number = int(re.findall(r'\\d+', post_number)[0])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_number\n",
        "\n",
        "\n",
        "def get_horseforum_post_url_path(post):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        The url path to the post, if successful, otherwise \"\"\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_url_path = \"\"\n",
        "    try:\n",
        "        post_url_path = post.find('a', { 'qid' : \"post-number\"})['href']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_url_path\n",
        "\n",
        "\n",
        "def get_horseforum_post_reactions_url_path(post):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        The url path to the post's reactions, if successful, otherwise \"\"\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_reactions_url_path = \"\"\n",
        "    try:\n",
        "        post_reactions_url_path = post.find('a', class_=\"reactionsBar-link\")['href']\n",
        "        if post_reactions_url_path[-1] != '/':\n",
        "            post_reactions_url_path = post_reactions_url_path + '/'\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_reactions_url_path\n",
        "\n",
        "\n",
        "\n",
        "def get_horseforum_post_reactions(post, url_domain):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "    str : url_domain\n",
        "        The base URL domain (including protocol) to be crawled (e.g., https://www.horseforum.com)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        The post's reactions, if successful, otherwise \"\"\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_reactions = \"\"\n",
        "    url_path = get_horseforum_post_reactions_url_path(soup)\n",
        "    if url_path != \"\":\n",
        "        response = requests.get(url_domain + url_path)\n",
        "        if response.status_code == 200:\n",
        "            reactions_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            try:\n",
        "                post_reactions = reactions_soup.find('span', class_=re.compile(r'reaction-text')).get_text()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    return post_reactions\n",
        "\n",
        "\n",
        "def get_horseforum_post_datetime(post):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        The datetime for the post, if successful, otherwise \"\"\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_datetime = \"\"\n",
        "    try:\n",
        "        post_datetime = post.find('div', class_=\"message-attribution-main\").find('time')['datetime']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_datetime\n",
        "\n",
        "\n",
        "def get_horseforum_post_username(post):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        The username for the post, if successful, otherwise \"\"\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_username = \"\"\n",
        "    try:\n",
        "        post_username = post.find('div', class_=\"message-userDetails\").find('a', class_=\"username\").get_text()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_username\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_horseforum_post_userid(post):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        The userid for the post, if successful, otherwise \"\"\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_username = \"\"\n",
        "    try:\n",
        "        post_username = post.find('div', class_=\"message-userDetails\").find('a', class_=\"username\")['data-user-id']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_username\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_horseforum_post_user_url_path(post):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        The url path to the user for the post, if successful, otherwise \"\"\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_user_url_path = \"\"\n",
        "    try:\n",
        "        post_user_url_path = post.find('div', class_=\"message-userDetails\").find('a', class_=\"username\")['href']\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_user_url_path\n",
        "\n",
        "\n",
        "def get_horseforum_post_text(post):\n",
        "    \"\"\"\n",
        "    Returns the message text of a post.\n",
        "\n",
        "    Note:\n",
        "    ----\n",
        "    Support for emoji within a post's text is done using image tags <img>, not characters.\n",
        "    However, the `get_text()` method of BeautifulSoup ignores image tags and hence the enoji are lost.\n",
        "    Hence the post's text is manually wrangled from the tag object of the post.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        The message text for the post, if successful, otherwise \"\"\n",
        "    \"\"\"\n",
        "    soup = post\n",
        "    post_text = \"\"\n",
        "    try:\n",
        "        post_text = post.find('article', { 'qid' : 'post-text'}).find('div')\n",
        "        post_text = str(post_text)\n",
        "        post_text = re.sub(r'^<[^>]+>|<[^>]+>$', '', post_text) # remove the outer div tags \n",
        "        post_text = re.sub(r'<img [^>]+ title=\"([^\"]+)\"[^>]*>', r'\\1', post_text) # Extract image's title attribute\n",
        "        post_text = re.sub(r'<br/>', r'\\n', post_text) # Replace line breaks\n",
        "        post_text = re.sub(r'<[^>]+>', r'', post_text) # Remove all remaining tags\n",
        "\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return post_text\n",
        "\n",
        "\n",
        "\n",
        "def scrape_horseforum_post(post, url_domain):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    -----------\n",
        "    bs4.BeautifulSoup : post\n",
        "        A BeautifulSoup object for the web page, being a 'post' within a \n",
        "        'thread' on the forum.\n",
        "    str : url_domain\n",
        "        The base URL domain (including protocol) to be crawled (e.g., https://www.horseforum.com)        \n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    list of dict {str, Any}\n",
        "        the predefined details of each thread-post:\n",
        "            + post_id\n",
        "            + post_number\n",
        "            + post_url_path\n",
        "            + post_reactions_url_path\n",
        "            + post_reactions\n",
        "            + post_datetime\n",
        "            + post_username\n",
        "            + post_userid\n",
        "            + post_user_url_path\n",
        "            + post_text\n",
        "\n",
        "    \"\"\"\n",
        "    post_id = get_horseforum_post_id(post)\n",
        "    post_number = get_horseforum_post_number(post)\n",
        "    post_url_path = get_horseforum_post_url_path(post)\n",
        "    post_reactions_url_path = get_horseforum_post_reactions_url_path(post)\n",
        "    post_reactions = get_horseforum_post_reactions(post, url_domain)\n",
        "    post_datetime = get_horseforum_post_datetime(post)\n",
        "    post_username = get_horseforum_post_username(post)\n",
        "    post_userid = get_horseforum_post_userid(post)\n",
        "    post_user_url_path = get_horseforum_post_user_url_path(post)\n",
        "    post_text = get_horseforum_post_text(post)\n",
        "\n",
        "    # Save result\n",
        "    dict_post = {\n",
        "        'post_id' : post_id\n",
        "        ,'post_number' : post_number\n",
        "        ,'post_url_path' : post_url_path\n",
        "        ,'post_reactions_url_path' : post_reactions_url_path\n",
        "        ,'post_reactions' : post_reactions\n",
        "        ,'post_datetime' : post_datetime\n",
        "        ,'post_username' : post_username\n",
        "        ,'post_userid' : post_userid\n",
        "        ,'post_user_url_path' : post_user_url_path\n",
        "        ,'post_text' : post_text\n",
        "        }\n",
        "       \n",
        "    return dict_post"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWLfQ4iBeDWw"
      },
      "source": [
        "### UDF crawler wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF_OplNgeGgk"
      },
      "source": [
        "def wrapper_web_crawler(\n",
        "    url_domain\n",
        "    ,list_url_path\n",
        "    ,fx_get_ResultSet\n",
        "    ,fx_get_ResultSet_data\n",
        "    ,fx_get_next_page_url\n",
        "    ,fx_get_page_data = None\n",
        "    ,max_pages = None\n",
        "    ,echo_every_n = 1\n",
        "    ,echo_page_crawl_every_n = 0\n",
        "    ,wait_thread_sec = 0\n",
        "    ,wait_page_sec = 0\n",
        "):\n",
        "\n",
        "    # Initialise\n",
        "    count_max = len(list_url_path)\n",
        "    df_forum_thread_posts = pd.DataFrame()\n",
        "    df_forum_thread_pages = pd.DataFrame()\n",
        "\n",
        "    # Crawl threads and scrape\n",
        "    start_time = time()\n",
        "    print('Crawl start UTC: {}'.format(datetime.fromtimestamp(start_time)))\n",
        "    for count, thread_url_path in enumerate(list_url_path):\n",
        "        # Show progress\n",
        "        if (echo_every_n > 0) and (count % echo_every_n == 0): # lazy evaluation\n",
        "            print(\"item {} of {}:\".format(count + 1, count_max))\n",
        "            print(\"\\t{}\".format(thread_url_path))\n",
        "\n",
        "        # Crawl pages and scrape\n",
        "        data_thread_posts, data_thread_pages = web_crawler(\n",
        "            url_domain =  url_domain\n",
        "            ,url_path = thread_url_path\n",
        "            ,fx_get_ResultSet = fx_get_ResultSet\n",
        "            ,fx_get_ResultSet_data = fx_get_ResultSet_data\n",
        "            ,fx_get_next_page_url = fx_get_next_page_url\n",
        "            ,fx_get_page_data = fx_get_page_data \n",
        "            ,max_pages = max_pages\n",
        "            ,echo_every_n = echo_page_crawl_every_n\n",
        "            ,wait_page_sec = wait_page_sec\n",
        "        )\n",
        "\n",
        "        # Convert thread's data to dataframe\n",
        "        df_thread_posts = pd.DataFrame(data_thread_posts)\n",
        "        df_thread_pages = pd.DataFrame(data_thread_pages)\n",
        "\n",
        "        # Add thread's url_path as unique key    \n",
        "        df_thread_posts.insert(0, 'thread_url_path', thread_url_path)\n",
        "        df_thread_pages.insert(0, 'thread_url_path', thread_url_path)\n",
        "\n",
        "        # Append to forum's dataframe\n",
        "        df_forum_thread_posts = pd.concat([df_forum_thread_posts, df_thread_posts])\n",
        "        df_forum_thread_pages = pd.concat([df_forum_thread_pages, df_thread_pages])\n",
        "\n",
        "        # Wait until crawling next thread\n",
        "        sleep(wait_thread_sec)\n",
        "\n",
        "    # Reset forum dataframe's index\n",
        "    df_forum_thread_posts.reset_index(inplace=True, drop=True)\n",
        "    df_forum_thread_pages.reset_index(inplace=True, drop=True)\n",
        "\n",
        "    end_time = time()\n",
        "    print(\"---crawl complete---\")\n",
        "    print()\n",
        "    print(\"Posts scraped: {}\".format(len(df_forum_thread_posts.index))) \n",
        "    print(\"Crawl time (sec): {0}\".format(end_time - start_time))\n",
        "    print('Crawl end UTC: {}'.format(datetime.fromtimestamp(end_time))) \n",
        "\n",
        "    return [df_forum_thread_posts, df_forum_thread_pages]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JnqurqHa9Ju"
      },
      "source": [
        "### Test: Crawl single thread"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikhH_jKia_or",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f45546-7898-4f8a-b981-0fbcff2d760d"
      },
      "source": [
        "# Specify which web page should be crawled\n",
        "url_domain =  \"https://www.horseforum.com\"\n",
        "url_path = \"/threads/the-care-of-an-emaciated-horse.100412/\" # note terminating '/'\n",
        "\n",
        "# Set functions relevant to scraping the web page\n",
        "get_ResultSet = get_horseforum_thread_page_posts\n",
        "get_ResultSet_data = lambda post: scrape_thread_post_details_horseforum(page_posts=post, url_domain=url_domain)\n",
        "get_next_page_url = get_horseforum_thread_page_next\n",
        "get_page_data = scrape_thread_page_details_horseforum\n",
        "\n",
        "# Crawl pages and scrape\n",
        "start_time = time()\n",
        "print('Crawl start UTC: {}'.format(datetime.fromtimestamp(start_time)))\n",
        "data_thread_posts, data_thread_pages = web_crawler(\n",
        "    url_domain =  url_domain\n",
        "    ,url_path = url_path\n",
        "    ,fx_get_ResultSet = get_ResultSet\n",
        "    ,fx_get_ResultSet_data = get_ResultSet_data\n",
        "    ,fx_get_next_page_url = get_next_page_url\n",
        "    ,fx_get_page_data = get_page_data \n",
        "    #,max_pages = 2\n",
        "    ,echo_every_n = 2\n",
        ")\n",
        "end_time = time()\n",
        "print(\"---crawl complete---\")\n",
        "print()\n",
        "print(\"Post count: {}\".format(len(data_thread_posts)))\n",
        "print(\"Crawl time (sec): {0}\".format(end_time - start_time))\n",
        "print('Crawl end UTC: {}'.format(datetime.fromtimestamp(end_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crawl start: 2021-11-30 13:07:54.593890\n",
            "Page 2, HTTP response status: 200\n",
            "\t20 items...\n",
            "---crawl complete---\n",
            "\n",
            "Post count: 55\n",
            "Crawl time (sec): 13.726727962493896\n",
            "Crawl start: 2021-11-30 13:08:08.320618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alvtK2OytlZd"
      },
      "source": [
        "### Crawl forum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEp170WtOOQH",
        "outputId": "7431d4e8-1d3a-4b6b-c59b-44547854035e"
      },
      "source": [
        "# Specify which web page should be crawled\n",
        "url_domain =  \"https://www.horseforum.com\"\n",
        "list_url_threads = df_horseforum_threads['item_url_path']\n",
        "print(\"Total thread count to crawl: {}\".format(len(list_url_threads)))\n",
        "\n",
        "# Set functions relevant to scraping the web page\n",
        "get_ResultSet = get_horseforum_thread_page_posts\n",
        "get_ResultSet_data = lambda post: scrape_thread_post_details_horseforum(page_posts=post, url_domain=url_domain)\n",
        "get_next_page_url = get_horseforum_thread_page_next\n",
        "get_page_data = scrape_thread_page_details_horseforum\n",
        "\n",
        "# Batch control: define \"chunks\" to crawl\n",
        "n_chunks = 20\n",
        "start_chunk = 3 # 1-base\n",
        "end_chunk = n_chunks # 1-base\n",
        "echo_every_n = 250\n",
        "wait_chunk_sec = 0\n",
        "\n",
        "#n_chunks = 20000\n",
        "#start_chunk = 25 # 1-base\n",
        "#end_chunk = 28 # 1-base\n",
        "\n",
        "print(\"Avg. chunk size (threads): {}\".format(len(list_url_threads) // 20))\n",
        "\n",
        "# Create a location to save crawler chunks\n",
        "filepath_chunks_save = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "filepath_chunks_save = os.path.join(filepath_data, filepath_chunks_save)\n",
        "#filepath_chunks_save = '/content/drive/MyDrive/Colab Notebooks/MA5851/Assessment 3/data/20211201-014114'\n",
        "\n",
        "flag_make_chunk_folder = mk_dir(filepath_chunks_save)\n",
        "if flag_make_chunk_folder:\n",
        "    print(\"Save location created: {}\".format(filepath_chunks_save))\n",
        "    print()\n",
        "else:\n",
        "    print(\"!!!Failed to create save location: {}\".format(filepath_chunks_save))\n",
        "\n",
        "if flag_make_chunk_folder:\n",
        "    start_main = time()\n",
        "    print('~~~~~~~~ Chunks crawl start ~~~~~~~~')\n",
        "    print('Main start UTC: {}'.format(datetime.fromtimestamp(start_main)))\n",
        "    print()\n",
        "\n",
        "    # Set filenames to save locally\n",
        "    filename_horseforum_posts_chunk_df = \"df_horseforum_posts_chunk{value:{fill}{align}{width}}.csv\"\n",
        "    filename_horseforum_pages_chunk_df = \"df_horseforum_pages_chunk{value:{fill}{align}{width}}.csv\"\n",
        "    pad_chunk = len(str(n_chunks)) # used for building chunk's filename\n",
        "\n",
        "    rge = range(df_horseforum_threads.shape[0])\n",
        "    for count_chunk, chunk in enumerate(np.array_split(np.array(rge), n_chunks)):\n",
        "        if count_chunk + 1 > end_chunk:\n",
        "            break\n",
        "        elif count_chunk + 1 >= start_chunk:\n",
        "            print(\"***** Chunk: {} *****\".format(count_chunk + 1))\n",
        "\n",
        "            # Crawl chunk of forum threads\n",
        "            df_forum_thread_posts_chunk, df_forum_thread_pages_chunk = wrapper_web_crawler(\n",
        "                url_domain = url_domain\n",
        "                ,list_url_path = list_url_threads[chunk]\n",
        "                ,fx_get_ResultSet = get_ResultSet\n",
        "                ,fx_get_ResultSet_data = get_ResultSet_data\n",
        "                ,fx_get_next_page_url = get_next_page_url\n",
        "                ,fx_get_page_data = get_page_data\n",
        "                #,max_pages = None\n",
        "                ,echo_every_n = echo_every_n\n",
        "                ,echo_page_crawl_every_n = 0\n",
        "                ,wait_thread_sec = 0\n",
        "                ,wait_page_sec = 0                \n",
        "            )\n",
        "\n",
        "            # Save dataframe locally\n",
        "            df_forum_thread_posts_chunk.to_csv(\n",
        "                os.path.join(filepath_chunks_save\n",
        "                            ,filename_horseforum_posts_chunk_df.format(value=count_chunk + 1, fill=0, align=\">\", width=pad_chunk)\n",
        "                            )\n",
        "                ,index=False)\n",
        "            \n",
        "            df_forum_thread_pages_chunk.to_csv(\n",
        "                os.path.join(filepath_chunks_save\n",
        "                            ,filename_horseforum_pages_chunk_df.format(value=count_chunk + 1, fill=0, align=\">\", width=pad_chunk)\n",
        "                            )\n",
        "                ,index=False)\n",
        "\n",
        "            print(\"*************************\")\n",
        "            print()\n",
        "\n",
        "            sleep(wait_chunk_sec)\n",
        "        else:\n",
        "            # skip this chunk\n",
        "            pass\n",
        "\n",
        "\n",
        "    end_main = time()\n",
        "    print(\"~~~~~~~~ Chunks crawl complete ~~~~~~~~ \")\n",
        "    print()\n",
        "    print(\"Duration time (sec): {0}\".format(end_main - start_main))\n",
        "    print('Main end UTC: {}'.format(datetime.fromtimestamp(end_main)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total thread count to crawl: 20954\n",
            "Avg. chunk size (threads): 1047\n",
            "Save location created: /content/drive/MyDrive/Colab Notebooks/MA5851/Assessment 3/data/20211201-014114\n",
            "\n",
            "~~~~~~~~ Chunks crawl start ~~~~~~~~\n",
            "Main start UTC: 2021-12-01 03:27:02.058748\n",
            "\n",
            "***** Chunk: 3 *****\n",
            "Crawl start UTC: 2021-12-01 03:27:02.064146\n",
            "item 1 of 1048:\n",
            "\t/threads/misdiagnosis-best-news-ever.787217/\n",
            "item 251 of 1048:\n",
            "\t/threads/orphan-weanling-care-5-6mo.727361/\n",
            "item 501 of 1048:\n",
            "\t/threads/does-soaking-grain-reduce-fiber-content.747689/\n",
            "item 751 of 1048:\n",
            "\t/threads/hemp-seed-oil.725809/\n",
            "item 1001 of 1048:\n",
            "\t/threads/vet-farrier-dentist-oh-my.704305/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 13219\n",
            "Crawl time (sec): 2176.2238006591797\n",
            "Crawl end UTC: 2021-12-01 04:03:18.287946\n",
            "*************************\n",
            "\n",
            "***** Chunk: 4 *****\n",
            "Crawl start UTC: 2021-12-01 04:03:18.712484\n",
            "item 1 of 1048:\n",
            "\t/threads/can-anyone-age-this-horse.700625/\n",
            "item 251 of 1048:\n",
            "\t/threads/purdue-equine-workshop.641802/\n",
            "item 501 of 1048:\n",
            "\t/threads/cellulitis-can-i-canter.640314/\n",
            "item 751 of 1048:\n",
            "\t/threads/hair-regrowth.618185/\n",
            "item 1001 of 1048:\n",
            "\t/threads/where-to-turn-next-with-horses-navicular.583386/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 11813\n",
            "Crawl time (sec): 1777.7950184345245\n",
            "Crawl end UTC: 2021-12-01 04:32:56.507502\n",
            "*************************\n",
            "\n",
            "***** Chunk: 5 *****\n",
            "Crawl start UTC: 2021-12-01 04:32:56.865320\n",
            "item 1 of 1048:\n",
            "\t/threads/new-1-year-old-donkey-has-many-health-issues.589994/\n",
            "item 251 of 1048:\n",
            "\t/threads/stifle-injury-and-beet-pulp.570482/\n",
            "item 501 of 1048:\n",
            "\t/threads/need-help-with-horse-again.546930/\n",
            "item 751 of 1048:\n",
            "\t/threads/supplement-help-please.524177/\n",
            "item 1001 of 1048:\n",
            "\t/threads/old-proud-flesh.500642/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 12383\n",
            "Crawl time (sec): 1590.5361156463623\n",
            "Crawl end UTC: 2021-12-01 04:59:27.401436\n",
            "*************************\n",
            "\n",
            "***** Chunk: 6 *****\n",
            "Crawl start UTC: 2021-12-01 04:59:27.726544\n",
            "item 1 of 1048:\n",
            "\t/threads/injured-horse-on-stall-rest-how-long-before-you-would-turn-out.495257/\n",
            "item 251 of 1048:\n",
            "\t/threads/hoof-supplements-that-work.473010/\n",
            "item 501 of 1048:\n",
            "\t/threads/what-is-wrong-with-my-gelding.450538/\n",
            "item 751 of 1048:\n",
            "\t/threads/anything-to-help-healing.422650/\n",
            "item 1001 of 1048:\n",
            "\t/threads/anyone-heard-this-about-cribbing.406498/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 11117\n",
            "Crawl time (sec): 1423.8838679790497\n",
            "Crawl end UTC: 2021-12-01 05:23:11.610412\n",
            "*************************\n",
            "\n",
            "***** Chunk: 7 *****\n",
            "Crawl start UTC: 2021-12-01 05:23:11.927289\n",
            "item 1 of 1048:\n",
            "\t/threads/seedy-toe.401642/\n",
            "item 251 of 1048:\n",
            "\t/threads/cough.374593/\n",
            "item 501 of 1048:\n",
            "\t/threads/sores-all-over-body-caused-by-hay.346425/\n",
            "item 751 of 1048:\n",
            "\t/threads/so-super-weird-question.321874/\n",
            "item 1001 of 1048:\n",
            "\t/threads/hock-injury.300969/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 10580\n",
            "Crawl time (sec): 1170.0760316848755\n",
            "Crawl end UTC: 2021-12-01 05:42:42.003321\n",
            "*************************\n",
            "\n",
            "***** Chunk: 8 *****\n",
            "Crawl start UTC: 2021-12-01 05:42:42.340841\n",
            "item 1 of 1048:\n",
            "\t/threads/how-do-you-suppose-my-6-year-old-has-osteoarthritis-advice-for-dealing-with-this.292961/\n",
            "item 251 of 1048:\n",
            "\t/threads/too-skinny-just-right-ribby-tb-weight-need-some-opnions-and-advice.272713/\n",
            "item 501 of 1048:\n",
            "\t/threads/what-should-i-feed-a-weanling.247857/\n",
            "item 751 of 1048:\n",
            "\t/threads/its-official.225698/\n",
            "item 1001 of 1048:\n",
            "\t/threads/major-weight-problem.24244/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 11588\n",
            "Crawl time (sec): 1177.3513197898865\n",
            "Crawl end UTC: 2021-12-01 06:02:19.692161\n",
            "*************************\n",
            "\n",
            "***** Chunk: 9 *****\n",
            "Crawl start UTC: 2021-12-01 06:02:19.992975\n",
            "item 1 of 1048:\n",
            "\t/threads/hear-something-when-she-breathes.194922/\n",
            "item 251 of 1048:\n",
            "\t/threads/age-determination-with-teeth.167481/\n",
            "item 501 of 1048:\n",
            "\t/threads/hind-end-off.153867/\n",
            "item 751 of 1048:\n",
            "\t/threads/hair-loss-help.151783/\n",
            "item 1001 of 1048:\n",
            "\t/threads/joint-care-for-my-barrel-every-riding-horse.148182/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 12984\n",
            "Crawl time (sec): 1232.4967503547668\n",
            "Crawl end UTC: 2021-12-01 06:22:52.489725\n",
            "*************************\n",
            "\n",
            "***** Chunk: 10 *****\n",
            "Crawl start UTC: 2021-12-01 06:22:52.817101\n",
            "item 1 of 1048:\n",
            "\t/threads/rolling-in-the-mud.147256/\n",
            "item 251 of 1048:\n",
            "\t/threads/keeping-horse-with-full-winter-coat-cool-during-riding.143793/\n",
            "item 501 of 1048:\n",
            "\t/threads/oral-medications-urhg.140892/\n",
            "item 751 of 1048:\n",
            "\t/threads/bright-yellos-discharge-in-nose-wth.137655/\n",
            "item 1001 of 1048:\n",
            "\t/threads/warning.134960/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 12277\n",
            "Crawl time (sec): 1067.9159452915192\n",
            "Crawl end UTC: 2021-12-01 06:40:40.733047\n",
            "*************************\n",
            "\n",
            "***** Chunk: 11 *****\n",
            "Crawl start UTC: 2021-12-01 06:40:41.100440\n",
            "item 1 of 1048:\n",
            "\t/threads/week-after-horse-trailer-rollover-check-up.134228/\n",
            "item 251 of 1048:\n",
            "\t/threads/my-horse-with-epm.131033/\n",
            "item 501 of 1048:\n",
            "\t/threads/speedy-graham-info-please.127803/\n",
            "item 751 of 1048:\n",
            "\t/threads/my-new-horse-has-a-bad-cut-on-her-front-hoof.124459/\n",
            "item 1001 of 1048:\n",
            "\t/threads/anyone-ever-buy-ulcer-meds-from-here.116692/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 11548\n",
            "Crawl time (sec): 910.3778638839722\n",
            "Crawl end UTC: 2021-12-01 06:55:51.478304\n",
            "*************************\n",
            "\n",
            "***** Chunk: 12 *****\n",
            "Crawl start UTC: 2021-12-01 06:55:51.764596\n",
            "item 1 of 1048:\n",
            "\t/threads/sore-on-my-horses-withers.119911/\n",
            "item 251 of 1048:\n",
            "\t/threads/vaccination-season-and-vee.117090/\n",
            "item 501 of 1048:\n",
            "\t/threads/gelding-joints-cracking.113664/\n",
            "item 751 of 1048:\n",
            "\t/threads/my-horse-has-a-cold.109657/\n",
            "item 1001 of 1048:\n",
            "\t/threads/hoof-boots.104720/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 12093\n",
            "Crawl time (sec): 893.2649867534637\n",
            "Crawl end UTC: 2021-12-01 07:10:45.029583\n",
            "*************************\n",
            "\n",
            "***** Chunk: 13 *****\n",
            "Crawl start UTC: 2021-12-01 07:10:45.359468\n",
            "item 1 of 1048:\n",
            "\t/threads/do-you-know-of-anyone-who-uses-one-of-these.105605/\n",
            "item 251 of 1048:\n",
            "\t/threads/how-is-he-lame.102673/\n",
            "item 501 of 1048:\n",
            "\t/threads/what-is-on-my-horses-eye-help.99441/\n",
            "item 751 of 1048:\n",
            "\t/threads/help-what-is-this-on-my-horses-legs.96818/\n",
            "item 1001 of 1048:\n",
            "\t/threads/tetanus-vaccines.93323/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 11306\n",
            "Crawl time (sec): 691.58971118927\n",
            "Crawl end UTC: 2021-12-01 07:22:16.949179\n",
            "*************************\n",
            "\n",
            "***** Chunk: 14 *****\n",
            "Crawl start UTC: 2021-12-01 07:22:17.242468\n",
            "item 1 of 1048:\n",
            "\t/threads/got-my-horse-on-tuesday-rode-for-2nd-time-today.92977/\n",
            "item 251 of 1048:\n",
            "\t/threads/thrush.90050/\n",
            "item 501 of 1048:\n",
            "\t/threads/is-it-safe-to-ride-him.87555/\n",
            "item 751 of 1048:\n",
            "\t/threads/past-prime-horses-that-just-never-slow-down-post-your-stories.84601/\n",
            "item 1001 of 1048:\n",
            "\t/threads/fattening-up-an-older-ottb.81584/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 10265\n",
            "Crawl time (sec): 462.3724834918976\n",
            "Crawl end UTC: 2021-12-01 07:29:59.614952\n",
            "*************************\n",
            "\n",
            "***** Chunk: 15 *****\n",
            "Crawl start UTC: 2021-12-01 07:29:59.879067\n",
            "item 1 of 1047:\n",
            "\t/threads/how-to-moving-horses-from-pasture-living-to-dry-lot.81087/\n",
            "item 251 of 1047:\n",
            "\t/threads/when-you-need-to-call-the-vet.77834/\n",
            "item 501 of 1047:\n",
            "\t/threads/new-to-the-forum-need-advice-on-adding-weight-to-an-old-horse.71621/\n",
            "item 751 of 1047:\n",
            "\t/threads/rugging-dilemma.70829/\n",
            "item 1001 of 1047:\n",
            "\t/threads/sunflower-seeds.62861/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 11212\n",
            "Crawl time (sec): 478.9925262928009\n",
            "Crawl end UTC: 2021-12-01 07:37:58.871593\n",
            "*************************\n",
            "\n",
            "***** Chunk: 16 *****\n",
            "Crawl start UTC: 2021-12-01 07:37:59.177703\n",
            "item 1 of 1047:\n",
            "\t/threads/salt-lick-vs-loose-minerals.65933/\n",
            "item 251 of 1047:\n",
            "\t/threads/avoiding-founder-on-pasture.63060/\n",
            "item 501 of 1047:\n",
            "\t/threads/curious-about-feet-trimming.60260/\n",
            "item 751 of 1047:\n",
            "\t/threads/how-much-turnout-does-your-horse-get.57319/\n",
            "item 1001 of 1047:\n",
            "\t/threads/sheath-cleaning.54541/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 11707\n",
            "Crawl time (sec): 505.7029230594635\n",
            "Crawl end UTC: 2021-12-01 07:46:24.880626\n",
            "*************************\n",
            "\n",
            "***** Chunk: 17 *****\n",
            "Crawl start UTC: 2021-12-01 07:46:25.225095\n",
            "item 1 of 1047:\n",
            "\t/threads/bump-on-leg.53713/\n",
            "item 251 of 1047:\n",
            "\t/threads/barn-sugestions.50389/\n",
            "item 501 of 1047:\n",
            "\t/threads/whats-worse-for-a-horse-opinionss.47028/\n",
            "item 751 of 1047:\n",
            "\t/threads/diet-critique-questions-suggestions.43198/\n",
            "item 1001 of 1047:\n",
            "\t/threads/abcess-blowout-question.40346/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 12338\n",
            "Crawl time (sec): 515.6412038803101\n",
            "Crawl end UTC: 2021-12-01 07:55:00.866299\n",
            "*************************\n",
            "\n",
            "***** Chunk: 18 *****\n",
            "Crawl start UTC: 2021-12-01 07:55:01.208462\n",
            "item 1 of 1047:\n",
            "\t/threads/worming.39679/\n",
            "item 251 of 1047:\n",
            "\t/threads/advice-on-diet-help.36809/\n",
            "item 501 of 1047:\n",
            "\t/threads/foot-sore.33967/\n",
            "item 751 of 1047:\n",
            "\t/threads/aggressive-new-horse.30622/\n",
            "item 1001 of 1047:\n",
            "\t/threads/boas-and-coronary-rubs.27725/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 10721\n",
            "Crawl time (sec): 482.01001954078674\n",
            "Crawl end UTC: 2021-12-01 08:03:03.218481\n",
            "*************************\n",
            "\n",
            "***** Chunk: 19 *****\n",
            "Crawl start UTC: 2021-12-01 08:03:03.506891\n",
            "item 1 of 1047:\n",
            "\t/threads/how-do-i-get-rid-of-a-capped-hock.27354/\n",
            "item 251 of 1047:\n",
            "\t/threads/stringhalt-epm.6199/\n",
            "item 501 of 1047:\n",
            "\t/threads/what-to-feed.20581/\n",
            "item 751 of 1047:\n",
            "\t/threads/is-abscess-often-mistaken-for-laminitis.17181/\n",
            "item 1001 of 1047:\n",
            "\t/threads/am-i-feeding-him-right.13536/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 10897\n",
            "Crawl time (sec): 463.65389919281006\n",
            "Crawl end UTC: 2021-12-01 08:10:47.160790\n",
            "*************************\n",
            "\n",
            "***** Chunk: 20 *****\n",
            "Crawl start UTC: 2021-12-01 08:10:47.412803\n",
            "item 1 of 1047:\n",
            "\t/threads/horse-with-stiff-neck.13036/\n",
            "item 251 of 1047:\n",
            "\t/threads/i-need-some-information-on-teeth.9372/\n",
            "item 501 of 1047:\n",
            "\t/threads/need-help-deciphering-mysterious-tattoo.6711/\n",
            "item 751 of 1047:\n",
            "\t/threads/sweet-itch-what-is-it.3586/\n",
            "item 1001 of 1047:\n",
            "\t/threads/i-need-help-with-my-horse-he-has.859/\n",
            "---crawl complete---\n",
            "\n",
            "Posts scraped: 8870\n",
            "Crawl time (sec): 428.60627126693726\n",
            "Crawl end UTC: 2021-12-01 08:17:56.019074\n",
            "*************************\n",
            "\n",
            "~~~~~~~~ Chunks crawl complete ~~~~~~~~ \n",
            "\n",
            "Duration time (sec): 17454.211379289627\n",
            "Main end UTC: 2021-12-01 08:17:56.270128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "seOjWM2aP9Ma",
        "outputId": "ac079a4a-a642-4662-d700-d982c851c2f8"
      },
      "source": [
        "# Combine hosreforum post chunks\n",
        "chunk_files = glob.glob(\n",
        "    os.path.join(filepath_chunks_save\n",
        "                 ,filename_horseforum_posts_chunk_df.format(value=\"*\", fill=\"\", align=\">\", width=1))\n",
        "    )\n",
        "\n",
        "ldf = [] # list of dataframes\n",
        "for filename in chunk_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    ldf.append(df)\n",
        "df_horseforum_thread_posts = pd.concat(ldf, axis=0, ignore_index=True)\n",
        "\n",
        "# save combine dateframe locally\n",
        "df_horseforum_thread_posts.to_csv(os.path.join(filepath_data, filename_horseforum_thread_posts_df), index=False)\n",
        "\n",
        "# display\n",
        "df_horseforum_thread_posts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>thread_url_path</th>\n",
              "      <th>post_id</th>\n",
              "      <th>post_number</th>\n",
              "      <th>post_url_path</th>\n",
              "      <th>post_reactions_url_path</th>\n",
              "      <th>post_reactions</th>\n",
              "      <th>post_datetime</th>\n",
              "      <th>post_username</th>\n",
              "      <th>post_userid</th>\n",
              "      <th>post_user_url_path</th>\n",
              "      <th>post_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/threads/please-read-before-posting-both-older...</td>\n",
              "      <td>post-1970931865</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/threads/please-read-before-posting-both-older...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-12-27T19:19:33-0500</td>\n",
              "      <td>TaMMa89</td>\n",
              "      <td>3542.0</td>\n",
              "      <td>/members/tamma89.3542/</td>\n",
              "      <td>New Horseforum.com format was launched in Nove...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>post-1970473609</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>/posts/1970473609/reactions/</td>\n",
              "      <td>Like (2)</td>\n",
              "      <td>2018-01-01T22:03:05-0500</td>\n",
              "      <td>Smilie</td>\n",
              "      <td>18361.0</td>\n",
              "      <td>/members/smilie.18361/</td>\n",
              "      <td>MOD NOTE (Jaydee)\\n\\nPlease could we keep this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>post-1970473615</td>\n",
              "      <td>2.0</td>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-01-01T22:22:01-0500</td>\n",
              "      <td>k9kenai</td>\n",
              "      <td>257833.0</td>\n",
              "      <td>/members/k9kenai.257833/</td>\n",
              "      <td>The most common around New Mexico is Braken Fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>post-1970473753</td>\n",
              "      <td>3.0</td>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-01-02T09:04:30-0500</td>\n",
              "      <td>QtrBel</td>\n",
              "      <td>33711.0</td>\n",
              "      <td>/members/qtrbel.33711/</td>\n",
              "      <td>http://www.aces.edu/pubs/docs/A/ANR-0975/ANR-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>post-1970473821</td>\n",
              "      <td>4.0</td>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-01-02T09:50:56-0500</td>\n",
              "      <td>egrogan</td>\n",
              "      <td>24027.0</td>\n",
              "      <td>/members/egrogan.24027/</td>\n",
              "      <td>The red maple is one we have to worry about a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232758</th>\n",
              "      <td>/threads/loose-stool.101/</td>\n",
              "      <td>post-469</td>\n",
              "      <td>10.0</td>\n",
              "      <td>/threads/loose-stool.101/post-469</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006-12-10T09:50:22-0500</td>\n",
              "      <td>child in time</td>\n",
              "      <td>118.0</td>\n",
              "      <td>/members/child-in-time.118/</td>\n",
              "      <td>Did you have called a vet?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232759</th>\n",
              "      <td>/threads/loose-stool.101/</td>\n",
              "      <td>post-479</td>\n",
              "      <td>11.0</td>\n",
              "      <td>/threads/loose-stool.101/post-479</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006-12-10T21:52:11-0500</td>\n",
              "      <td>Cedarsgirl</td>\n",
              "      <td>120.0</td>\n",
              "      <td>/members/cedarsgirl.120/</td>\n",
              "      <td>Yup, vets aware of her condition. First he tho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232760</th>\n",
              "      <td>/threads/quietex.49/</td>\n",
              "      <td>post-170</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/threads/quietex.49/post-170</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006-11-14T23:17:30-0500</td>\n",
              "      <td>KristyMarie87</td>\n",
              "      <td>65.0</td>\n",
              "      <td>/members/kristymarie87.65/</td>\n",
              "      <td>I have a 4 year old Paint Gelding who is very ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232761</th>\n",
              "      <td>/threads/quietex.49/</td>\n",
              "      <td>post-172</td>\n",
              "      <td>2.0</td>\n",
              "      <td>/threads/quietex.49/post-172</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006-11-15T23:06:17-0500</td>\n",
              "      <td>sweetwaterarabians</td>\n",
              "      <td>67.0</td>\n",
              "      <td>/members/sweetwaterarabians.67/</td>\n",
              "      <td>Hi\\n\\n\\n\\nSorry your boy is so fussy with the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232762</th>\n",
              "      <td>/threads/quietex.49/</td>\n",
              "      <td>post-197</td>\n",
              "      <td>3.0</td>\n",
              "      <td>/threads/quietex.49/post-197</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006-11-20T11:19:12-0500</td>\n",
              "      <td>OhSnapItsRoxy</td>\n",
              "      <td>77.0</td>\n",
              "      <td>/members/ohsnapitsroxy.77/</td>\n",
              "      <td>Been there!\\n\\n\\n\\nWhile Quietex may help calm...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>232763 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          thread_url_path  ...                                          post_text\n",
              "0       /threads/please-read-before-posting-both-older...  ...  New Horseforum.com format was launched in Nove...\n",
              "1       /threads/poisonous-plants-from-hf-member-locat...  ...  MOD NOTE (Jaydee)\\n\\nPlease could we keep this...\n",
              "2       /threads/poisonous-plants-from-hf-member-locat...  ...  The most common around New Mexico is Braken Fe...\n",
              "3       /threads/poisonous-plants-from-hf-member-locat...  ...  http://www.aces.edu/pubs/docs/A/ANR-0975/ANR-0...\n",
              "4       /threads/poisonous-plants-from-hf-member-locat...  ...  The red maple is one we have to worry about a ...\n",
              "...                                                   ...  ...                                                ...\n",
              "232758                          /threads/loose-stool.101/  ...                         Did you have called a vet?\n",
              "232759                          /threads/loose-stool.101/  ...  Yup, vets aware of her condition. First he tho...\n",
              "232760                               /threads/quietex.49/  ...  I have a 4 year old Paint Gelding who is very ...\n",
              "232761                               /threads/quietex.49/  ...  Hi\\n\\n\\n\\nSorry your boy is so fussy with the ...\n",
              "232762                               /threads/quietex.49/  ...  Been there!\\n\\n\\n\\nWhile Quietex may help calm...\n",
              "\n",
              "[232763 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Rj7ceujQGSxB",
        "outputId": "ddeebb5a-5779-41e7-95b1-47aece259dfc"
      },
      "source": [
        "# Combine hosreforum page chunks\n",
        "chunk_files = glob.glob(\n",
        "    os.path.join(filepath_chunks_save\n",
        "                 ,filename_horseforum_pages_chunk_df.format(value=\"*\", fill=\"\", align=\">\", width=1))\n",
        "    )\n",
        "\n",
        "ldf = [] # list of dataframes\n",
        "for filename in chunk_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    ldf.append(df)\n",
        "df_horseforum_thread_pages = pd.concat(ldf, axis=0, ignore_index=True)\n",
        "\n",
        "# save combine dateframe locally\n",
        "df_horseforum_thread_pages.to_csv(os.path.join(filepath_data, filename_horseforum_thread_pages_df), index=False)\n",
        "\n",
        "# display\n",
        "df_horseforum_thread_pages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>thread_url_path</th>\n",
              "      <th>participant_count</th>\n",
              "      <th>page_url_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/threads/please-read-before-posting-both-older...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>/threads/please-read-before-posting-both-older...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>/threads/poisonous-plants-from-hf-member-locat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/threads/the-care-of-an-emaciated-horse.100412/</td>\n",
              "      <td>31.0</td>\n",
              "      <td>/threads/the-care-of-an-emaciated-horse.100412/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/threads/the-care-of-an-emaciated-horse.100412/</td>\n",
              "      <td>31.0</td>\n",
              "      <td>/threads/the-care-of-an-emaciated-horse.100412...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/threads/the-care-of-an-emaciated-horse.100412/</td>\n",
              "      <td>31.0</td>\n",
              "      <td>/threads/the-care-of-an-emaciated-horse.100412...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24622</th>\n",
              "      <td>/threads/recovery-from-torn-rear-suspensory-li...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>/threads/recovery-from-torn-rear-suspensory-li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24623</th>\n",
              "      <td>/threads/how-to-get-horses-to-gaine-weight.99/</td>\n",
              "      <td>9.0</td>\n",
              "      <td>/threads/how-to-get-horses-to-gaine-weight.99/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24624</th>\n",
              "      <td>/threads/paxil.102/</td>\n",
              "      <td>4.0</td>\n",
              "      <td>/threads/paxil.102/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24625</th>\n",
              "      <td>/threads/loose-stool.101/</td>\n",
              "      <td>4.0</td>\n",
              "      <td>/threads/loose-stool.101/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24626</th>\n",
              "      <td>/threads/quietex.49/</td>\n",
              "      <td>3.0</td>\n",
              "      <td>/threads/quietex.49/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24627 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         thread_url_path  ...                                      page_url_path\n",
              "0      /threads/please-read-before-posting-both-older...  ...  /threads/please-read-before-posting-both-older...\n",
              "1      /threads/poisonous-plants-from-hf-member-locat...  ...  /threads/poisonous-plants-from-hf-member-locat...\n",
              "2        /threads/the-care-of-an-emaciated-horse.100412/  ...    /threads/the-care-of-an-emaciated-horse.100412/\n",
              "3        /threads/the-care-of-an-emaciated-horse.100412/  ...  /threads/the-care-of-an-emaciated-horse.100412...\n",
              "4        /threads/the-care-of-an-emaciated-horse.100412/  ...  /threads/the-care-of-an-emaciated-horse.100412...\n",
              "...                                                  ...  ...                                                ...\n",
              "24622  /threads/recovery-from-torn-rear-suspensory-li...  ...  /threads/recovery-from-torn-rear-suspensory-li...\n",
              "24623     /threads/how-to-get-horses-to-gaine-weight.99/  ...     /threads/how-to-get-horses-to-gaine-weight.99/\n",
              "24624                                /threads/paxil.102/  ...                                /threads/paxil.102/\n",
              "24625                          /threads/loose-stool.101/  ...                          /threads/loose-stool.101/\n",
              "24626                               /threads/quietex.49/  ...                               /threads/quietex.49/\n",
              "\n",
              "[24627 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wh6Ty5JCaZU"
      },
      "source": [
        "### Reload crawled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyvCpkcXfVYn",
        "outputId": "27708560-6d65-4450-88cb-f48fd1aafbd0"
      },
      "source": [
        "df_horseforum_thread_posts = pd.read_csv(os.path.join(filepath_data, filename_horseforum_thread_posts_df))\n",
        "print(\"Re-imported posts data: {x[0]} rows × {x[1]} cols\".format(x = df_horseforum_thread_posts.shape))\n",
        "df_horseforum_thread_pages = pd.read_csv(os.path.join(filepath_data, filename_horseforum_thread_pages_df))\n",
        "print(\"Re-imported pages data {x[0]} rows × {x[1]} cols\".format(x = df_horseforum_thread_pages.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-imported posts data: 232763 rows × 11 cols\n",
            "Re-imported pages data 24627 rows × 3 cols\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzmTHlcI3JB"
      },
      "source": [
        "## Python notebook (.ipynb) conversion to HTML\n",
        "\n",
        "The following code cell was for converting this Python notebook (.ipynb) to HTML (.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjv0JTJ1H7Yl",
        "outputId": "fd7da62a-7db4-4c3e-a130-0ffb92aab14c"
      },
      "source": [
        "# Conversion of notebook to html (Google Colab):\n",
        "filename_Notebook_ipynb = 'A3_Lachlan_Sharp.ipynb'\n",
        "filename_Notebook_ipynb = '\\\"' + os.path.join(filepath_root, filename_Notebook_ipynb) + '\\\"'\n",
        "\n",
        "!jupyter nbconvert --to html $filename_Notebook_ipynb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab Notebooks/MA5851/Assessment 3/A3_Lachlan_Sharp.ipynb to html\n",
            "[NbConvertApp] Writing 496442 bytes to /content/drive/MyDrive/Colab Notebooks/MA5851/Assessment 3/A3_Lachlan_Sharp.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aytN6S5FJOI8"
      },
      "source": [
        "# Conversion of notebook to pdf (Google Colab):\n",
        "\n",
        "#!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "#!pip install pypandoc\n",
        "#!jupyter nbconvert --to PDF $filename_Notebook_ipynb"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}